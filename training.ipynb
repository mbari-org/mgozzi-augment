{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Deepsea Network\n",
    "This project incorporates wandb directly inside the YOLOv5 network (wandb support was added by ultralytics). This notebook allows us to retrain the model and see how train time augmentations can improve the networks ability to detect and track objects without increasing the data sample size. \n",
    "\n",
    "## Notes\n",
    "Training using the ml.p3.2xlarge is about 10x faster ml.g4dn.large which makes the p3 more cost effective. \n",
    "\n",
    "## Known Issues\n",
    "When running the training script in quick succession on the g4dn.xlarge, a memory issue may arise. Shut down the running instance and wait for the machine to become available again and restart the program. This seems to be an issue related to YOLOv5 and Sagemaker's use of a RAM partition as \"storage.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.2.2 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 5)) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 6)) (1.22.2)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 7)) (4.5.5.62)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 8)) (9.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 9)) (5.4.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 10)) (2.27.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 11)) (1.8.0)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 12)) (1.10.2+cu113)\n",
      "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 13)) (0.11.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 14)) (4.62.3)\n",
      "Requirement already satisfied: protobuf<4.21.3 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 15)) (3.19.4)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 18)) (2.9.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 22)) (1.4.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 23)) (0.11.2)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 35)) (8.0.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 36)) (5.9.0)\n",
      "Requirement already satisfied: thop in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 37)) (0.1.1.post2207130030)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r deepsea-yolov5/yolov5/requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r deepsea-yolov5/yolov5/requirements.txt (line 5)) (3.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r deepsea-yolov5/yolov5/requirements.txt (line 5)) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r deepsea-yolov5/yolov5/requirements.txt (line 5)) (4.29.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r deepsea-yolov5/yolov5/requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r deepsea-yolov5/yolov5/requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.23.0->-r deepsea-yolov5/yolov5/requirements.txt (line 10)) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.23.0->-r deepsea-yolov5/yolov5/requirements.txt (line 10)) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.23.0->-r deepsea-yolov5/yolov5/requirements.txt (line 10)) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.23.0->-r deepsea-yolov5/yolov5/requirements.txt (line 10)) (3.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r deepsea-yolov5/yolov5/requirements.txt (line 12)) (4.1.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (1.47.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (0.37.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (1.1.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (2.0.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (60.9.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (3.3.7)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (2.9.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (0.6.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.1.4->-r deepsea-yolov5/yolov5/requirements.txt (line 22)) (2021.3)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (2.12.0)\n",
      "Requirement already satisfied: black in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (22.1.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.1.3)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (3.0.29)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.18.1)\n",
      "Requirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (5.1.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.7.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (1.3.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (4.11.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.2.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.8/site-packages (from black->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.4.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (8.0.4)\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.8/site-packages (from black->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (2.5.1)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (2.0.1)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.9.0)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.2.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (3.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: wandb in /opt/conda/lib/python3.8/site-packages (0.12.21)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (8.0.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from wandb) (60.9.3)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.0.9)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.7.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.27.1)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.19.4)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.1.27)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.8/site-packages (from wandb) (1.2.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.7)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "!pip install -r deepsea-yolov5/yolov5/requirements.txt\n",
    "!pip install wandb\n",
    "!wandb login # append wandb login key here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Images into Train and Validate Categories\n",
    "In order to make the data useable with YOLOv5 we need to split the single images directory into a training set and a validation set. The labels to benchmark against are have the same name as the images they correspond to, but with a .txt filename."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the images found in the tar.gz file into the /opt/ml/input/data directory.\n",
    "```\n",
    "deepsea-yolov5\n",
    "  ├── opt/ml/data\n",
    "  │   ├── images\n",
    "  │   └── labels\n",
    " ...\n",
    " ```\n",
    " The files will be mutated into the following structure upon running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "Using default path /root/mgozzi-augment/deepsea-yolov5/src/../opt/ml/input/data\n",
      "    Creating: /root/mgozzi-augment/deepsea-yolov5/src/../opt/ml/input/data/images/train\n",
      "    Creating: /root/mgozzi-augment/deepsea-yolov5/src/../opt/ml/input/data/images/val\n",
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "!python ./deepsea-yolov5/src/split.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " ```\n",
    "deepsea-yolov5\n",
    "  ├── opt/ml/data\n",
    "  │   ├── images\n",
    "  │   │   ├── train\n",
    "  │   │   │   ├── image1.png\n",
    "  │   │   │   └── ...\n",
    "  │   │   └── val\n",
    "  │   │       ├── image12345.png\n",
    "  │   │       └── ...\n",
    "  │   ├── labels\n",
    "  │   └──...\n",
    " ...\n",
    " ```\n",
    "Run the following script in your terminal of choice in the root of the deepsea-yolov5 directory\n",
    "<code>python .\\src\\split.py</code>\n",
    "<br>This will split the image directory into training and validation directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training For Evolutions\n",
    "This will train the network and output the results of the generations to wandb. The best generation will be saved to data/hyps folder under the YOLOv5 directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdcline\u001b[0m (\u001b[33mmbari\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=./deepsea-yolov5/yolov5/models/yolov5s.yaml, data=./deepsea-yolov5/opt/ml/custom_config.yaml, hyp=deepsea-yolov5/yolov5/data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=2, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=30, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=902005-vaa, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 4 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.1-291-ga84cd02 Python-3.8.10 torch-1.10.2+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220713_233916-3lz3rkka\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgrateful-wildflower-261\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3lz3rkka\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=3\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "[2022-07-13 23:39:19.428 pytorch-1-10-gpu-py-ml-g4dn-xlarge-bd81d1f288c5d63d0571c57fb0b0:993 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2022-07-13 23:39:19.559 pytorch-1-10-gpu-py-ml-g4dn-xlarge-bd81d1f288c5d63d0571c57fb0b0:993 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:33<00:00, 33.0\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.16 anchors/target, 0.045 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 6.95 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.529-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.508G    0.1027   0.03647   0.07474         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.508G   0.07373   0.03417   0.06733         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.508G   0.06878    0.0317   0.06379         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9     0.51G   0.05901   0.03083   0.06162        17       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9     0.51G   0.05408   0.02982   0.05845         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9     0.51G   0.04943   0.02998   0.05442         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9     0.51G   0.04579   0.02883   0.05021         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9     0.51G   0.04398   0.02814   0.04805         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9     0.51G    0.0431   0.02916   0.04447         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9     0.51G   0.04043   0.02832   0.04174         7       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.464      0.499      0.406      0.208\n",
      "\n",
      "10 epochs completed in 0.166 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▆▅▅▄▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▆▄▃▂▃▂▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.40617\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.20788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.46364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.49911\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.40617\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.20788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.46364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.49911\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.04174\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgrateful-wildflower-261\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3lz3rkka\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220713_233916-3lz3rkka/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m1 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.46364,              0.49911,              0.40617,              0.20788,             0.037682,             0.025173,             0.039845,                 0.01,                 0.01,                0.937,               0.0005,                    3,                  0.8,                  0.1,                 0.05,                  0.5,                    1,                    1,                    1,                  0.2,                    4,                    0,                0.015,                  0.7,                  0.4,                    0,                  0.1,                  0.5,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                    3\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00916, lrf=0.01, momentum=0.97664, weight_decay=0.0005, warmup_epochs=3.14742, warmup_momentum=0.8, warmup_bias_lr=0.1407, box=0.05559, cls=0.5, cls_pw=1.165, obj=0.9827, obj_pw=1.05444, iou_t=0.2, anchor_t=3.65455, fl_gamma=0.0, hsv_h=0.01619, hsv_s=0.70914, hsv_v=0.39067, degrees=0.0, translate=0.10866, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.24165\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220713_235002-1j7si7tb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdenim-wind-262\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1j7si7tb\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.24165\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.1\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.02 anchors/target, 0.008 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7740: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.27: 0.9988 best possible recall, 4.90 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.485/0.774-mean/best, past_thr=0.550-mean: 20,18, 35,25, 32,44, 51,41, 69,67, 131,104\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.508G     0.111   0.03904   0.08179         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.508G    0.0819   0.03359   0.07274         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9     0.51G   0.07507   0.03399   0.06651         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9     0.51G   0.06798   0.03443   0.06201         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9     0.51G   0.05835   0.03244   0.05691         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9     0.51G   0.05429   0.03368   0.05314         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9     0.51G   0.05175   0.03187    0.0501         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9     0.51G   0.04984   0.03145   0.04691         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9     0.51G   0.04864    0.0309   0.04276         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9     0.51G   0.04767   0.03017   0.04036         1       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616       0.42      0.477      0.419      0.223\n",
      "\n",
      "10 epochs completed in 0.165 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▄▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▄▄▄▃▄▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.41888\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.22265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.41992\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.47706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.41888\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.22265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.41992\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.47706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04767\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.04036\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.03017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04341\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03802\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02792\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdenim-wind-262\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1j7si7tb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220713_235002-1j7si7tb/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m2 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.41992,              0.47706,              0.41888,              0.22265,             0.043408,             0.027918,             0.038024,              0.00916,                 0.01,              0.97664,               0.0005,               3.1474,                  0.8,               0.1407,              0.05559,                  0.5,                1.165,               0.9827,               1.0544,                  0.2,               3.6545,                    0,              0.01619,              0.70914,              0.39067,                    0,              0.10866,                  0.5,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.2416\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00924, lrf=0.01, momentum=0.98, weight_decay=0.00048, warmup_epochs=3.1474, warmup_momentum=0.8, warmup_bias_lr=0.12587, box=0.05547, cls=0.48065, cls_pw=1.20679, obj=0.93888, obj_pw=1.03722, iou_t=0.2, anchor_t=3.6545, fl_gamma=0.0, hsv_h=0.01657, hsv_s=0.70914, hsv_v=0.35783, degrees=0.0, translate=0.10275, scale=0.52925, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.95185, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_000044-2aah8o8y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstill-dew-263\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2aah8o8y\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00048\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.2\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.02 anchors/target, 0.008 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7740: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.27: 0.9988 best possible recall, 4.90 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.485/0.774-mean/best, past_thr=0.550-mean: 20,18, 35,25, 32,44, 51,41, 69,67, 131,104\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.508G      0.11    0.0364   0.08125         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.508G   0.08101   0.03153   0.07281         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9     0.51G   0.07425    0.0318   0.06851         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9     0.51G   0.06752   0.03156   0.06263         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9     0.51G    0.0612   0.03017   0.05764         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9     0.51G   0.05659   0.03062    0.0533         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9     0.51G   0.05275   0.03028   0.04983         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9     0.51G   0.05072   0.03019   0.04617         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9     0.51G   0.04877   0.03085   0.04218         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9     0.51G   0.04701   0.02903   0.04152         4       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.427      0.444      0.395      0.206\n",
      "\n",
      "10 epochs completed in 0.164 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▆▅▄▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▃▄▃▂▃▂▂▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.39535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.20641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.42704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.44358\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.39535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.20641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.42704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.44358\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.04152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.04106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mstill-dew-263\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2aah8o8y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_000044-2aah8o8y/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m3 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.42704,              0.44358,              0.39535,              0.20641,             0.044369,             0.026975,             0.041063,              0.00924,                 0.01,                 0.98,              0.00048,               3.1474,                  0.8,              0.12587,              0.05547,              0.48065,               1.2068,              0.93888,               1.0372,                  0.2,               3.6545,                    0,              0.01657,              0.70914,              0.35783,                    0,              0.10275,              0.52925,                    0,                    0,                    0,                  0.5,              0.95185,                    0,                    0,                    2\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00996, lrf=0.01, momentum=0.87764, weight_decay=0.00051, warmup_epochs=3.3181, warmup_momentum=0.88452, warmup_bias_lr=0.1, box=0.05095, cls=0.513, cls_pw=0.8867, obj=0.82079, obj_pw=1.0, iou_t=0.2, anchor_t=3.79229, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.88469, hsv_v=0.4, degrees=0.0, translate=0.09347, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.79099, mixup=0.0, copy_paste=0.0, anchors=3.0\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_001119-1q0irh5k\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mglorious-sunset-264\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1q0irh5k\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=3.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00051\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.3\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.14 anchors/target, 0.038 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.26: 1.0000 best possible recall, 6.79 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.536-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9     0.51G    0.0997   0.02885   0.06837         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9     0.51G   0.07026   0.02651   0.06261         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9     0.51G    0.0672   0.02551   0.06101         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9     0.51G   0.06255   0.02476   0.05981        22       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9     0.51G   0.05755   0.02447   0.05755         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9     0.51G   0.05231   0.02275    0.0553         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.512G   0.04887   0.02294   0.05335         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.512G   0.04704   0.02176   0.05114         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.512G   0.04334   0.02139   0.04986         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.512G   0.04162   0.02285    0.0482         3       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.275       0.34      0.231      0.125\n",
      "\n",
      "10 epochs completed in 0.162 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▄▄▄▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▄▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▆▅▄▄▂▂▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆███▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆███▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.23094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.12541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.27451\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.3397\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.23094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.12541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.27451\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.3397\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.04814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mglorious-sunset-264\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1q0irh5k\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_001119-1q0irh5k/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m4 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.27451,               0.3397,              0.23094,              0.12541,             0.038524,             0.021957,             0.048139,              0.00996,                 0.01,              0.87764,              0.00051,               3.3181,              0.88452,                  0.1,              0.05095,                0.513,               0.8867,              0.82079,                    1,                  0.2,               3.7923,                    0,                0.015,              0.88469,                  0.4,                    0,              0.09347,                  0.5,                    0,                    0,                    0,                  0.5,              0.79099,                    0,                    0,                    3\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00919, lrf=0.01, momentum=0.96386, weight_decay=0.00047, warmup_epochs=3.11146, warmup_momentum=0.84667, warmup_bias_lr=0.12587, box=0.05845, cls=0.48313, cls_pw=1.19036, obj=0.93888, obj_pw=1.0372, iou_t=0.2, anchor_t=3.55444, fl_gamma=0.0, hsv_h=0.01657, hsv_s=0.70914, hsv_v=0.35783, degrees=0.0, translate=0.09628, scale=0.52925, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.95938, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_002146-360mm81g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbalmy-breeze-265\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/360mm81g\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00047\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.2\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.02 anchors/target, 0.007 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7668: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.28: 0.9959 best possible recall, 4.51 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.464/0.768-mean/best, past_thr=0.559-mean: 24,20, 27,36, 45,30, 50,50, 84,72, 198,187\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.493G    0.1111   0.03418   0.07994         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.493G   0.08203   0.03055   0.07004         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.493G   0.07692   0.03036   0.06448         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.493G   0.07175   0.02901   0.05932         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.493G   0.06178    0.0284   0.05524         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.493G    0.0581   0.02774    0.0514         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.493G   0.05356   0.02707   0.04964         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.493G   0.05104   0.02719   0.04605         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.493G   0.04837   0.02683   0.04212         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.493G   0.04808   0.02643   0.04096         8       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616       0.41      0.506      0.394      0.205\n",
      "\n",
      "10 epochs completed in 0.163 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▄▄▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▅▅▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.39374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.20497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.40957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.50604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.39374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.20497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.40957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.50604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04808\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.04096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02643\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03859\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02452\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mbalmy-breeze-265\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/360mm81g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_002146-360mm81g/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m5 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.40957,              0.50604,              0.39374,              0.20497,             0.046639,             0.024524,             0.038589,              0.00919,                 0.01,              0.96386,              0.00047,               3.1115,              0.84667,              0.12587,              0.05845,              0.48313,               1.1904,              0.93888,               1.0372,                  0.2,               3.5544,                    0,              0.01657,              0.70914,              0.35783,                    0,              0.09628,              0.52925,                    0,                    0,                    0,                  0.5,              0.95938,                    0,                    0,                    2\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00919, lrf=0.01, momentum=0.96673, weight_decay=0.00047, warmup_epochs=3.00787, warmup_momentum=0.84667, warmup_bias_lr=0.11953, box=0.05595, cls=0.43996, cls_pw=1.23069, obj=0.97639, obj_pw=1.0372, iou_t=0.2, anchor_t=3.82665, fl_gamma=0.0, hsv_h=0.01657, hsv_s=0.70914, hsv_v=0.35783, degrees=0.0, translate=0.09628, scale=0.52925, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.95938, mixup=0.0, copy_paste=0.0, anchors=2.00729\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_003220-1crapz77\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwarm-fire-266\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1crapz77\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.00729\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00047\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.2\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.03 anchors/target, 0.009 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7637: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.26: 0.9971 best possible recall, 4.47 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.447/0.764-mean/best, past_thr=0.546-mean: 24,21, 30,41, 46,31, 58,56, 106,87, 230,229\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.493G    0.1057   0.03478   0.07495         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.493G   0.07785   0.03116   0.06629         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.493G   0.07412   0.03109   0.06283         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.493G   0.06384   0.03065   0.05777         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.493G   0.05851   0.02887   0.05341         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.493G   0.05402   0.02819   0.04978         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.493G   0.05029   0.02732     0.047         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.493G   0.04744   0.02769   0.04307         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.493G   0.04562   0.02739   0.03939         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.493G   0.04509   0.02682   0.03765         8       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.399      0.489       0.38      0.203\n",
      "\n",
      "10 epochs completed in 0.163 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▆▅▄▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▅▅▄▃▂▁▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.37957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.20251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.39867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.48918\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.37957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.20251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.39867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.48918\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04509\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.03765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02682\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04264\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03722\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mwarm-fire-266\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1crapz77\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_003220-1crapz77/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m6 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.39867,              0.48918,              0.37957,              0.20251,             0.042636,             0.024684,             0.037225,              0.00919,                 0.01,              0.96673,              0.00047,               3.0079,              0.84667,              0.11953,              0.05595,              0.43996,               1.2307,              0.97639,               1.0372,                  0.2,               3.8266,                    0,              0.01657,              0.70914,              0.35783,                    0,              0.09628,              0.52925,                    0,                    0,                    0,                  0.5,              0.95938,                    0,                    0,               2.0073\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00903, lrf=0.01071, momentum=0.96386, weight_decay=0.00045, warmup_epochs=2.96406, warmup_momentum=0.84667, warmup_bias_lr=0.12587, box=0.06045, cls=0.47024, cls_pw=1.1904, obj=0.90473, obj_pw=1.16916, iou_t=0.2, anchor_t=3.80405, fl_gamma=0.0, hsv_h=0.01698, hsv_s=0.63999, hsv_v=0.35783, degrees=0.0, translate=0.08859, scale=0.52925, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.95938, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_004253-1ot38bk6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbumbling-monkey-267\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1ot38bk6\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00045\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.1\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.03 anchors/target, 0.009 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7668: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.26: 0.9980 best possible recall, 4.64 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.463/0.767-mean/best, past_thr=0.550-mean: 24,20, 29,39, 41,28, 52,49, 83,73, 205,199\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.499G    0.1161   0.03607   0.07834         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.499G   0.08525   0.03262   0.06907         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.499G   0.08153   0.03205   0.06509         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.499G   0.07246   0.03211    0.0607         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.499G   0.06213    0.0307   0.05699         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.499G   0.05863   0.02981    0.0537         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.499G   0.05521   0.02875   0.05163         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.499G   0.05343   0.02926   0.04852         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.499G   0.05072   0.02864   0.04433         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.499G   0.04951   0.02804   0.04297         8       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.346      0.505      0.346      0.186\n",
      "\n",
      "10 epochs completed in 0.164 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▄▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▅▄▅▃▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆██▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆██▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.34604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.18611\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.34649\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.50533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.34604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.18611\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.34649\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.50533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04951\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.04297\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02804\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.04179\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02619\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mbumbling-monkey-267\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1ot38bk6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_004253-1ot38bk6/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m7 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.34649,              0.50533,              0.34604,              0.18611,             0.047077,             0.026186,             0.041788,              0.00903,              0.01071,              0.96386,              0.00045,               2.9641,              0.84667,              0.12587,              0.06045,              0.47024,               1.1904,              0.90473,               1.1692,                  0.2,               3.8041,                    0,              0.01698,              0.63999,              0.35783,                    0,              0.08859,              0.52925,                    0,                    0,                    0,                  0.5,              0.95938,                    0,                    0,                    2\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01243, lrf=0.01, momentum=0.88843, weight_decay=0.00055, warmup_epochs=2.79469, warmup_momentum=0.84667, warmup_bias_lr=0.13358, box=0.07813, cls=0.48313, cls_pw=0.9876, obj=0.93888, obj_pw=1.29986, iou_t=0.2, anchor_t=3.5544, fl_gamma=0.0, hsv_h=0.01809, hsv_s=0.70914, hsv_v=0.38813, degrees=0.0, translate=0.10758, scale=0.64403, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.95938, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_005328-2nlnxvxn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meager-meadow-268\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2nlnxvxn\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00055\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.1\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.02 anchors/target, 0.007 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7668: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.28: 0.9959 best possible recall, 4.51 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.464/0.768-mean/best, past_thr=0.559-mean: 24,20, 27,36, 45,30, 50,50, 84,72, 198,187\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.493G    0.1436   0.03933   0.06952         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.493G    0.1118   0.03585   0.06284         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.493G     0.107   0.03659    0.0626         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.493G   0.09943   0.03616   0.06117         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.493G   0.08704   0.03255   0.05882         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.493G   0.08109   0.03141   0.05702         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.493G   0.07469   0.03056   0.05566         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.493G   0.06822   0.03149   0.05391         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.493G   0.06363   0.03048   0.05138         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.493G   0.06202   0.03016   0.05102         8       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.458      0.356      0.247      0.141\n",
      "\n",
      "10 epochs completed in 0.164 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▅▄▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▅▅▄▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▅▆▆▃▂▁▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▄▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆██▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆██▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.24661\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.14069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.45784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.35561\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.24661\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.14069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.45784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.35561\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.06202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.05102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.03016\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.05766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.05221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33meager-meadow-268\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2nlnxvxn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_005328-2nlnxvxn/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m8 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.45784,              0.35561,              0.24661,              0.14069,             0.057664,             0.027878,             0.052205,              0.01243,                 0.01,              0.88843,              0.00055,               2.7947,              0.84667,              0.13358,              0.07813,              0.48313,               0.9876,              0.93888,               1.2999,                  0.2,               3.5544,                    0,              0.01809,              0.70914,              0.38813,                    0,              0.10758,              0.64403,                    0,                    0,                    0,                  0.5,              0.95938,                    0,                    0,                    2\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00844, lrf=0.01, momentum=0.94076, weight_decay=0.00039, warmup_epochs=3.1391, warmup_momentum=0.84667, warmup_bias_lr=0.12508, box=0.0577, cls=0.42281, cls_pw=1.25844, obj=0.89371, obj_pw=1.09134, iou_t=0.2, anchor_t=3.5544, fl_gamma=0.0, hsv_h=0.01622, hsv_s=0.75064, hsv_v=0.35783, degrees=0.0, translate=0.08961, scale=0.56466, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.9829, mixup=0.0, copy_paste=0.0, anchors=2.70219\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_010403-152pi8i9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlegendary-yogurt-269\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/152pi8i9\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.70219\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00039\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.1\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.12 anchors/target, 0.034 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.28: 1.0000 best possible recall, 6.55 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.546-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.501G    0.1146   0.03386   0.07521         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.501G   0.08082   0.03102   0.06758         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.501G   0.07566   0.02941   0.06489         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.501G   0.06763   0.02786   0.06247         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.501G   0.06169   0.02681    0.0594         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.501G   0.05415   0.02782   0.05597         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.503G   0.05185   0.02491   0.05338         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.503G   0.04964   0.02537   0.05198         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.503G   0.04683    0.0257   0.04992         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.503G   0.04572   0.02523   0.04727         3       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.321      0.412      0.294      0.163\n",
      "\n",
      "10 epochs completed in 0.165 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▄▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▆▅▃▂▃▁▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.29402\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.1631\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.32135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.41156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.29402\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.1631\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.32135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.41156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04572\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.04727\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.04757\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02311\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlegendary-yogurt-269\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/152pi8i9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_010403-152pi8i9/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m9 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.32135,              0.41156,              0.29402,               0.1631,             0.043792,             0.023111,             0.047566,              0.00844,                 0.01,              0.94076,              0.00039,               3.1391,              0.84667,              0.12508,               0.0577,              0.42281,               1.2584,              0.89371,               1.0913,                  0.2,               3.5544,                    0,              0.01622,              0.75064,              0.35783,                    0,              0.08961,              0.56466,                    0,                    0,                    0,                  0.5,               0.9829,                    0,                    0,               2.7022\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00907, lrf=0.01009, momentum=0.97389, weight_decay=0.00049, warmup_epochs=3.1115, warmup_momentum=0.73926, warmup_bias_lr=0.12587, box=0.06286, cls=0.48673, cls_pw=1.24445, obj=0.79848, obj_pw=1.06217, iou_t=0.2, anchor_t=3.56357, fl_gamma=0.0, hsv_h=0.0149, hsv_s=0.744, hsv_v=0.3339, degrees=0.0, translate=0.09491, scale=0.50039, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.9914, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_011444-q99nk4pp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwobbly-microwave-270\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/q99nk4pp\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00049\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.0\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.02 anchors/target, 0.007 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7752: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.28: 0.9980 best possible recall, 4.89 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.489/0.776-mean/best, past_thr=0.554-mean: 20,18, 32,25, 29,43, 48,39, 65,66, 127,92\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.499G    0.1265   0.03363   0.08485         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.499G   0.09275   0.02953    0.0756         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.499G   0.08561   0.02885   0.07096        13       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.499G    0.0752   0.02823   0.06513         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.499G   0.06644    0.0284   0.05967         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.499G   0.06126   0.02748    0.0551         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.499G   0.05795   0.02594   0.05177         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.499G   0.05597   0.02556   0.04826        22       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.499G    0.0532   0.02714   0.04477         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.499G   0.05296   0.02491   0.04256         7       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.439      0.463      0.401      0.205\n",
      "\n",
      "10 epochs completed in 0.165 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▆▅▄▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▅▄▄▄▃▂▂▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.40069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.20518\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.43853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.46288\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.40069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.20518\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.43853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.46288\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.05296\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.04256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04872\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.04135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02343\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mwobbly-microwave-270\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/q99nk4pp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_011444-q99nk4pp/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m10 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.43853,              0.46288,              0.40069,              0.20518,             0.048719,             0.023426,             0.041346,              0.00907,              0.01009,              0.97389,              0.00049,               3.1115,              0.73926,              0.12587,              0.06286,              0.48673,               1.2445,              0.79848,               1.0622,                  0.2,               3.5636,                    0,               0.0149,                0.744,               0.3339,                    0,              0.09491,              0.50039,                    0,                    0,                    0,                  0.5,               0.9914,                    0,                    0,                    2\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00924, lrf=0.01, momentum=0.95871, weight_decay=0.00045, warmup_epochs=3.22712, warmup_momentum=0.8, warmup_bias_lr=0.12587, box=0.05547, cls=0.48914, cls_pw=1.15554, obj=0.95491, obj_pw=1.00384, iou_t=0.2, anchor_t=3.68581, fl_gamma=0.0, hsv_h=0.01657, hsv_s=0.68159, hsv_v=0.39818, degrees=0.0, translate=0.10372, scale=0.52925, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.98511, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_012526-32ltt5ln\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdry-eon-271\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/32ltt5ln\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00045\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.1\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.02 anchors/target, 0.008 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7637: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.27: 0.9971 best possible recall, 4.41 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.449/0.764-mean/best, past_thr=0.551-mean: 23,21, 30,40, 44,30, 58,54, 101,88, 232,206\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.493G    0.1083   0.03377   0.07958         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.493G      0.08   0.02969   0.07067         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.493G    0.0736   0.02867   0.06553         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.493G   0.06841   0.02858   0.05956         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.493G    0.0585   0.02748    0.0545         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.493G   0.05447   0.02707   0.05077         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.493G   0.04944   0.02646   0.04728         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.493G   0.04786   0.02566   0.04335         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.493G   0.04544   0.02642   0.04074         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.493G   0.04381   0.02533   0.03721         6       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.506      0.522      0.469      0.251\n",
      "\n",
      "10 epochs completed in 0.164 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▆▅▄▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▅▄▄▃▂▂▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆█▇▇▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆█▇▇▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.46907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.50573\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.5219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.46907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.50573\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.5219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.03721\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdry-eon-271\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/32ltt5ln\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_012526-32ltt5ln/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m11 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.50573,               0.5219,              0.46907,                0.251,             0.041406,             0.022564,             0.035346,              0.00924,                 0.01,              0.95871,              0.00045,               3.2271,                  0.8,              0.12587,              0.05547,              0.48914,               1.1555,              0.95491,               1.0038,                  0.2,               3.6858,                    0,              0.01657,              0.68159,              0.39818,                    0,              0.10372,              0.52925,                    0,                    0,                    0,                  0.5,              0.98511,                    0,                    0,                    2\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00917, lrf=0.01, momentum=0.98, weight_decay=0.00047, warmup_epochs=3.3557, warmup_momentum=0.75864, warmup_bias_lr=0.16133, box=0.06539, cls=0.5, cls_pw=1.165, obj=0.99944, obj_pw=1.0544, iou_t=0.2, anchor_t=3.39689, fl_gamma=0.0, hsv_h=0.01629, hsv_s=0.70914, hsv_v=0.45791, degrees=0.0, translate=0.10866, scale=0.48098, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.82685, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_013601-n04sqxso\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmild-music-272\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/n04sqxso\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00047\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 33.9\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.01 anchors/target, 0.004 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7674: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.29: 0.9959 best possible recall, 4.47 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.469/0.768-mean/best, past_thr=0.565-mean: 22,19, 28,36, 44,27, 49,46, 79,68, 187,168\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.499G    0.1277   0.03787   0.08256         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.499G   0.09444   0.03177   0.07392         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.499G   0.08719    0.0319   0.06875         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.499G   0.07888   0.03077   0.06405         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.499G   0.07278   0.03021    0.0607         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.499G   0.06568   0.03053    0.0564         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.499G   0.06276   0.02918   0.05383         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.499G   0.05977   0.02899    0.0504         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.499G   0.05742    0.0281   0.04751        13       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.499G   0.05558   0.02796   0.04568         4       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.484      0.385      0.345      0.172\n",
      "\n",
      "10 epochs completed in 0.165 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▄▄▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▄▄▃▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆███▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆███▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.34522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.17176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.484\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.38478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.34522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.17176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.484\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.38478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.05558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.04568\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.05276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.04465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02732\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmild-music-272\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/n04sqxso\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_013601-n04sqxso/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m12 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m               0.484,              0.38478,              0.34522,              0.17176,             0.052758,             0.027325,             0.044647,              0.00917,                 0.01,                 0.98,              0.00047,               3.3557,              0.75864,              0.16133,              0.06539,                  0.5,                1.165,              0.99944,               1.0544,                  0.2,               3.3969,                    0,              0.01629,              0.70914,              0.45791,                    0,              0.10866,              0.48098,                    0,                    0,                    0,                  0.5,              0.82685,                    0,                    0,                    2\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0104, lrf=0.01, momentum=0.97664, weight_decay=0.00039, warmup_epochs=3.06715, warmup_momentum=0.7725, warmup_bias_lr=0.11424, box=0.04113, cls=0.49746, cls_pw=1.37685, obj=0.82211, obj_pw=1.0544, iou_t=0.2, anchor_t=3.82787, fl_gamma=0.0, hsv_h=0.01883, hsv_s=0.9, hsv_v=0.39067, degrees=0.0, translate=0.08602, scale=0.54967, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_014641-1p759zxb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstellar-breeze-273\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1p759zxb\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00039\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.0\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.03 anchors/target, 0.009 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7638: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.26: 0.9971 best possible recall, 4.47 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.448/0.764-mean/best, past_thr=0.546-mean: 24,21, 31,41, 46,31, 58,56, 105,87, 230,229\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.493G   0.08446   0.02996   0.09187         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.493G   0.06277   0.02575   0.07891         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.495G   0.05815   0.02551   0.06682         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.495G   0.05289    0.0259   0.05711         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.495G   0.04587   0.02522     0.051         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.495G   0.04347   0.02602   0.04634         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.495G   0.03982   0.02529   0.04265         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.495G   0.03892   0.02491   0.04001         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.495G   0.03789   0.02442   0.03519         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.495G   0.03697   0.02435     0.034         0       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.559      0.568      0.552      0.285\n",
      "\n",
      "10 epochs completed in 0.160 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▄▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▃▂▃▂▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.55205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.28504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.55907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.5684\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.55205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.28504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.55907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.5684\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03697\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00216\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00216\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00216\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mstellar-breeze-273\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1p759zxb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_014641-1p759zxb/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m13 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.55907,               0.5684,              0.55205,              0.28504,             0.033511,             0.021653,             0.029161,               0.0104,                 0.01,              0.97664,              0.00039,               3.0671,               0.7725,              0.11424,              0.04113,              0.49746,               1.3768,              0.82211,               1.0544,                  0.2,               3.8279,                    0,              0.01883,                  0.9,              0.39067,                    0,              0.08602,              0.54967,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                    2\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00916, lrf=0.01252, momentum=0.92393, weight_decay=0.00052, warmup_epochs=2.9119, warmup_momentum=0.8, warmup_bias_lr=0.16502, box=0.05559, cls=0.51437, cls_pw=1.02699, obj=0.87619, obj_pw=1.0544, iou_t=0.2, anchor_t=3.6545, fl_gamma=0.0, hsv_h=0.01222, hsv_s=0.82902, hsv_v=0.40476, degrees=0.0, translate=0.115, scale=0.63277, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_015703-37zpm6fm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwandering-pyramid-274\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/37zpm6fm\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00052\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.0\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.02 anchors/target, 0.008 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7740: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.27: 0.9988 best possible recall, 4.90 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.485/0.774-mean/best, past_thr=0.550-mean: 20,18, 35,25, 32,44, 51,41, 69,67, 131,104\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.499G    0.1124   0.03426   0.07634         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.499G   0.08407    0.0308   0.06953         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.501G   0.07795    0.0303   0.06627         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.501G   0.07348   0.03129   0.06334         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.501G   0.06135   0.02885   0.05831         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.501G   0.05625   0.02917   0.05553         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.501G   0.05138   0.02748   0.05248         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.501G   0.05007   0.02741   0.04991         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.501G   0.04708   0.02672   0.04699         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.501G   0.04605   0.02659   0.04562         0       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.378      0.446      0.358      0.192\n",
      "\n",
      "10 epochs completed in 0.160 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▆▅▄▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▅▄▅▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆██▇▆▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆██▇▆▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.358\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.19207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.37753\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.44635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.358\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.19207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.37753\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.44635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04605\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.04562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02659\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.04381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mwandering-pyramid-274\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/37zpm6fm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_015703-37zpm6fm/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m14 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.37753,              0.44635,                0.358,              0.19207,             0.042083,             0.025862,             0.043806,              0.00916,              0.01252,              0.92393,              0.00052,               2.9119,                  0.8,              0.16502,              0.05559,              0.51437,                1.027,              0.87619,               1.0544,                  0.2,               3.6545,                    0,              0.01222,              0.82902,              0.40476,                    0,                0.115,              0.63277,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                    2\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00917, lrf=0.01001, momentum=0.97574, weight_decay=0.0005, warmup_epochs=3.16298, warmup_momentum=0.80018, warmup_bias_lr=0.14046, box=0.05562, cls=0.5, cls_pw=1.16595, obj=0.98448, obj_pw=1.0544, iou_t=0.2, anchor_t=3.68008, fl_gamma=0.0, hsv_h=0.01616, hsv_s=0.70949, hsv_v=0.3923, degrees=0.0, translate=0.1086, scale=0.49875, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.2416\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_020726-2kq9gbn5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstoic-donkey-275\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2kq9gbn5\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.2416\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.1\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.02 anchors/target, 0.008 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7767: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.27: 0.9988 best possible recall, 4.93 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.487/0.777-mean/best, past_thr=0.550-mean: 20,17, 29,25, 33,45, 49,34, 65,62, 131,94\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.493G    0.1117   0.03933   0.08186         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.493G   0.08135   0.03446    0.0733         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.495G   0.07513    0.0342   0.06737         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.495G   0.06834   0.03459   0.06178         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.495G   0.05969   0.03279   0.05661         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.495G   0.05486   0.03364   0.05191         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.495G    0.0515   0.03183   0.04863         2       640: 100%|███/9    0.495G   0.05152   0.03193   0.04848         3       640:  85%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.495G    0.0492   0.03147   0.04511         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.495G   0.04836   0.03073    0.0416         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.495G   0.04704   0.03032   0.03956         1       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616       0.46      0.521      0.451       0.23\n",
      "\n",
      "10 epochs completed in 0.163 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▆▅▄▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▄▄▄▃▄▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆█▇▇▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆█▇▇▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.45127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.23047\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.45986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.52085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.45127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.23047\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.45986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.52085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.03956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.03032\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03665\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mstoic-donkey-275\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2kq9gbn5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_020726-2kq9gbn5/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m15 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.45986,              0.52085,              0.45127,              0.23047,             0.043872,             0.027732,             0.036654,              0.00917,              0.01001,              0.97574,               0.0005,                3.163,              0.80018,              0.14046,              0.05562,                  0.5,                1.166,              0.98448,               1.0544,                  0.2,               3.6801,                    0,              0.01616,              0.70949,               0.3923,                    0,               0.1086,              0.49875,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.2416\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00952, lrf=0.01, momentum=0.95451, weight_decay=0.0005, warmup_epochs=3.53925, warmup_momentum=0.70995, warmup_bias_lr=0.10571, box=0.05157, cls=0.40067, cls_pw=1.23831, obj=1.13558, obj_pw=1.03711, iou_t=0.2, anchor_t=3.71624, fl_gamma=0.0, hsv_h=0.01186, hsv_s=0.70914, hsv_v=0.40067, degrees=0.0, translate=0.12027, scale=0.47882, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.59382\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_021757-6sbk4lyi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgenial-rain-276\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/6sbk4lyi\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.59382\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 33.5\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.13 anchors/target, 0.036 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.27: 1.0000 best possible recall, 6.72 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.539-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.503G    0.1113   0.04024   0.07249         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.503G   0.07936   0.03853   0.06448         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.503G   0.07115    0.0354   0.06086         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.503G   0.06608   0.03343   0.05868        17       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.503G   0.05683   0.03364     0.056         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.503G   0.04925   0.03409   0.05177         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.503G    0.0479   0.03268   0.04831         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.503G     0.045   0.03192   0.04705         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.503G   0.04308   0.03271   0.04407         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.503G   0.04123   0.03169   0.04179         6       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.468       0.44       0.36      0.189\n",
      "\n",
      "10 epochs completed in 0.173 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▄▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▇▄▂▃▃▂▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▃▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▅███▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▅███▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.3602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.1888\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.46845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.44041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.3602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.1888\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.46845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.44041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.04179\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.03169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.04062\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgenial-rain-276\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/6sbk4lyi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_021757-6sbk4lyi/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m16 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.46845,              0.44041,               0.3602,               0.1888,             0.039653,             0.028727,             0.040615,              0.00952,                 0.01,              0.95451,               0.0005,               3.5393,              0.70995,              0.10571,              0.05157,              0.40067,               1.2383,               1.1356,               1.0371,                  0.2,               3.7162,                    0,              0.01186,              0.70914,              0.40067,                    0,              0.12027,              0.47882,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.5938\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00919, lrf=0.01, momentum=0.97998, weight_decay=0.00049, warmup_epochs=3.03388, warmup_momentum=0.81087, warmup_bias_lr=0.1407, box=0.05714, cls=0.4872, cls_pw=1.165, obj=1.00317, obj_pw=1.07347, iou_t=0.2, anchor_t=3.57198, fl_gamma=0.0, hsv_h=0.01622, hsv_s=0.74712, hsv_v=0.37246, degrees=0.0, translate=0.10986, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.99606, mixup=0.0, copy_paste=0.0, anchors=2.45759\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_022908-1lksnefc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msandy-sky-277\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1lksnefc\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.45759\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00049\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 33.5\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.02 anchors/target, 0.007 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7664: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.28: 0.9955 best possible recall, 4.51 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.463/0.768-mean/best, past_thr=0.558-mean: 23,20, 28,37, 43,30, 51,51, 86,74, 202,188\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.499G    0.1104    0.0382   0.07955         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.499G   0.08176   0.03282    0.0713         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.501G   0.07681   0.03216   0.06665         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.501G   0.06507   0.03241   0.06012        25       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.501G   0.06067   0.03183    0.0555         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.501G   0.05499   0.03231   0.05226         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.501G   0.05218   0.02971   0.04926         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.501G   0.05075   0.02916   0.04562         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.501G   0.04911   0.03049   0.04256         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.501G   0.04744   0.02785   0.04022         1       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.398      0.536      0.397       0.21\n",
      "\n",
      "10 epochs completed in 0.168 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▆▅▄▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▄▄▄▄▄▂▂▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.3973\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.2103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.3977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.53639\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.3973\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.2103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.3977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.53639\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04744\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.04022\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04564\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03927\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msandy-sky-277\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1lksnefc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_022908-1lksnefc/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m17 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m              0.3977,              0.53639,               0.3973,               0.2103,             0.045645,             0.026457,             0.039267,              0.00919,                 0.01,              0.97998,              0.00049,               3.0339,              0.81087,               0.1407,              0.05714,               0.4872,                1.165,               1.0032,               1.0735,                  0.2,                3.572,                    0,              0.01622,              0.74712,              0.37246,                    0,              0.10986,                  0.5,                    0,                    0,                    0,                  0.5,              0.99606,                    0,                    0,               2.4576\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0101, lrf=0.01, momentum=0.98, weight_decay=0.00048, warmup_epochs=3.23835, warmup_momentum=0.8, warmup_bias_lr=0.1407, box=0.0531, cls=0.48902, cls_pw=1.15816, obj=0.93868, obj_pw=1.01326, iou_t=0.2, anchor_t=3.66287, fl_gamma=0.0, hsv_h=0.01619, hsv_s=0.75068, hsv_v=0.43027, degrees=0.0, translate=0.11224, scale=0.48041, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.50236\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_024000-2n3fcgxq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmisty-blaze-278\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2n3fcgxq\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.50236\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00048\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 33.7\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.13 anchors/target, 0.035 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.27: 1.0000 best possible recall, 6.67 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.541-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.516G    0.1067   0.03402   0.08171         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.516G   0.07603   0.03153   0.07275         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.516G   0.06948   0.02909   0.06832         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.516G   0.06419   0.02765   0.06425        17       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.516G   0.05515   0.02751   0.06014         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.516G   0.05165   0.02808   0.05611         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.516G   0.04903   0.02735    0.0519         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.516G   0.04719    0.0269   0.05023         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.516G   0.04583   0.02744   0.04645         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.516G   0.04434   0.02706   0.04386         6       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.461      0.453       0.38      0.202\n",
      "\n",
      "10 epochs completed in 0.165 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▆▅▄▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▆▃▂▂▂▁▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆█▇▇▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆█▇▇▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.37969\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.20181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.46083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.4526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.37969\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.20181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.46083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.4526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04434\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.04386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04193\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.04091\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02373\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0021\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0021\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0021\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmisty-blaze-278\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2n3fcgxq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_024000-2n3fcgxq/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m18 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.46083,               0.4526,              0.37969,              0.20181,             0.041932,             0.023732,             0.040907,               0.0101,                 0.01,                 0.98,              0.00048,               3.2384,                  0.8,               0.1407,               0.0531,              0.48902,               1.1582,              0.93868,               1.0133,                  0.2,               3.6629,                    0,              0.01619,              0.75068,              0.43027,                    0,              0.11224,              0.48041,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.5024\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00959, lrf=0.01016, momentum=0.98, weight_decay=0.00054, warmup_epochs=3.32543, warmup_momentum=0.76676, warmup_bias_lr=0.1407, box=0.05559, cls=0.4562, cls_pw=1.17699, obj=1.08967, obj_pw=1.06931, iou_t=0.2, anchor_t=3.17795, fl_gamma=0.0, hsv_h=0.01573, hsv_s=0.74395, hsv_v=0.40446, degrees=0.0, translate=0.10566, scale=0.50898, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.99789, mixup=0.0, copy_paste=0.0, anchors=2.24422\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_025039-2cr3ltod\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstoic-snow-279\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2cr3ltod\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.24422\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00054\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 33.9\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.01 anchors/target, 0.002 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7683: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.31: 0.9939 best possible recall, 4.37 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.474/0.770-mean/best, past_thr=0.574-mean: 22,20, 40,26, 31,40, 54,46, 77,70, 163,152\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.499G    0.1096   0.04014   0.07513         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.499G   0.08122   0.03411   0.06783         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.499G   0.07489   0.03364    0.0635         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.499G   0.06723   0.03412   0.05839         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.499G   0.05712   0.03295   0.05339         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.499G   0.05408   0.03363   0.05012         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.499G   0.04961   0.03123   0.04674         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.499G   0.04894   0.03086   0.04386         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.499G   0.04639   0.03073   0.03995         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.499G   0.04576   0.02916   0.03857         1       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.481      0.422      0.406      0.208\n",
      "\n",
      "10 epochs completed in 0.164 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▆▅▄▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▄▄▄▃▄▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆███▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆███▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.40619\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.20813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.48067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.42208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.40619\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.20813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.48067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.42208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04576\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.03857\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04428\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02772\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mstoic-snow-279\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2cr3ltod\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_025039-2cr3ltod/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m19 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.48067,              0.42208,              0.40619,              0.20813,             0.044284,             0.027722,             0.037679,              0.00959,              0.01016,                 0.98,              0.00054,               3.3254,              0.76676,               0.1407,              0.05559,               0.4562,                1.177,               1.0897,               1.0693,                  0.2,                3.178,                    0,              0.01573,              0.74395,              0.40446,                    0,              0.10566,              0.50898,                    0,                    0,                    0,                  0.5,              0.99789,                    0,                    0,               2.2442\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01058, lrf=0.01154, momentum=0.98, weight_decay=0.00054, warmup_epochs=3.1474, warmup_momentum=0.8, warmup_bias_lr=0.14941, box=0.04518, cls=0.62898, cls_pw=1.1535, obj=0.9827, obj_pw=1.26244, iou_t=0.2, anchor_t=3.4235, fl_gamma=0.0, hsv_h=0.01843, hsv_s=0.62639, hsv_v=0.44436, degrees=0.0, translate=0.08824, scale=0.42356, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.2416\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_030114-1nf6hp4u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrose-sea-280\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1nf6hp4u\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.2416\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00054\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.0\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.01 anchors/target, 0.004 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7659: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.29: 0.9955 best possible recall, 4.39 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.460/0.767-mean/best, past_thr=0.564-mean: 23,20, 40,27, 31,42, 55,47, 84,75, 253,181\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.493G    0.0885   0.03965   0.09936         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.493G   0.06761   0.03276    0.0839         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.493G   0.06355     0.033   0.06989         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.493G   0.05887   0.03351   0.06175         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.493G   0.05031    0.0323   0.05413         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.493G   0.04585   0.03301     0.049         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.493G   0.04441   0.03235   0.04525         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.493G   0.04257   0.03189   0.04157         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.493G   0.04109   0.03116   0.03661         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.493G   0.04041   0.03055   0.03542         1       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.595      0.513        0.5      0.259\n",
      "\n",
      "10 epochs completed in 0.162 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▄▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▃▃▃▂▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆█▇▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.50042\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.25853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.59476\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.5128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.50042\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.25853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.59476\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.5128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.03542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.03055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03941\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02938\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mrose-sea-280\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1nf6hp4u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_030114-1nf6hp4u/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m20 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.59476,               0.5128,              0.50042,              0.25853,             0.039414,             0.029381,             0.035151,              0.01058,              0.01154,                 0.98,              0.00054,               3.1474,                  0.8,              0.14941,              0.04518,              0.62898,               1.1535,               0.9827,               1.2624,                  0.2,               3.4235,                    0,              0.01843,              0.62639,              0.44436,                    0,              0.08824,              0.42356,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.2416\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00746, lrf=0.011, momentum=0.96395, weight_decay=0.00035, warmup_epochs=3.93436, warmup_momentum=0.82183, warmup_bias_lr=0.10431, box=0.05897, cls=0.5, cls_pw=1.19724, obj=0.91279, obj_pw=0.92255, iou_t=0.2, anchor_t=4.53939, fl_gamma=0.0, hsv_h=0.01616, hsv_s=0.70949, hsv_v=0.42766, degrees=0.0, translate=0.06205, scale=0.44684, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.66384, mixup=0.0, copy_paste=0.0, anchors=2.89572\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_031144-2jq9xdjm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mruby-valley-281\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2jq9xdjm\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.89572\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00035\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 33.9\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.22 anchors/target, 0.060 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.22: 1.0000 best possible recall, 7.28 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.516-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.501G    0.1243   0.03026   0.08693         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.501G   0.08454   0.03012   0.07828         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.501G   0.07717   0.02815   0.07443         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.501G   0.07213   0.02602   0.07187         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.501G   0.06427     0.025   0.06842         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.501G   0.06213   0.02554   0.06413         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.501G   0.05629   0.02437   0.06037         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.501G    0.0544    0.0233   0.05788         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.501G    0.0511   0.02279   0.05462         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.501G   0.04935   0.02351    0.0522         5       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.353      0.445       0.34      0.174\n",
      "\n",
      "10 epochs completed in 0.161 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▄▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▄▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ██▆▄▃▄▂▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▆▃▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▅▇██▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▅▇██▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.33967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.17373\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.35303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.44462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.33967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.17373\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.35303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.44462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0476\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.04975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mruby-valley-281\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2jq9xdjm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_031144-2jq9xdjm/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m21 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.35303,              0.44462,              0.33967,              0.17373,               0.0476,              0.02398,              0.04975,              0.00746,                0.011,              0.96395,              0.00035,               3.9344,              0.82183,              0.10431,              0.05897,                  0.5,               1.1972,              0.91279,              0.92255,                  0.2,               4.5394,                    0,              0.01616,              0.70949,              0.42766,                    0,              0.06205,              0.44684,                    0,                    0,                    0,                  0.5,              0.66384,                    0,                    0,               2.8957\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00828, lrf=0.01001, momentum=0.98, weight_decay=0.00049, warmup_epochs=3.163, warmup_momentum=0.80018, warmup_bias_lr=0.14737, box=0.06477, cls=0.5, cls_pw=1.17785, obj=0.92074, obj_pw=0.93902, iou_t=0.2, anchor_t=4.05935, fl_gamma=0.0, hsv_h=0.01719, hsv_s=0.67973, hsv_v=0.3923, degrees=0.0, translate=0.11621, scale=0.54182, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.92212, mixup=0.0, copy_paste=0.0, anchors=3.11952\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_032211-2l9awlb5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcrisp-plant-282\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2l9awlb5\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=3.11952\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00049\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 33.9\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.17 anchors/target, 0.046 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 6.99 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.528-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.501G     0.132    0.0326   0.08446         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.501G    0.0936   0.03262   0.07568         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.501G   0.08476   0.02983   0.07307         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.501G   0.07676   0.02893   0.07009        30       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.501G   0.06685   0.02848   0.06643        10       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.501G   0.06459   0.02691   0.06336         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.501G   0.06154   0.02736   0.06076         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.501G   0.05845    0.0269   0.05838         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.501G   0.05711   0.02552   0.05579         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.501G   0.05619   0.02606   0.05346         3       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.312      0.454       0.29      0.145\n",
      "\n",
      "10 epochs completed in 0.162 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▄▄▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▄▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ██▅▄▄▂▃▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▆█▇▇▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▆█▇▇▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.28996\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.14539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.31167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.45354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.28996\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.14539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.31167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.45354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.05619\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.05346\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.05209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00172\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00172\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00172\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mcrisp-plant-282\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2l9awlb5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_032211-2l9awlb5/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m22 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.31167,              0.45354,              0.28996,              0.14539,             0.052704,             0.024184,             0.052092,              0.00828,              0.01001,                 0.98,              0.00049,                3.163,              0.80018,              0.14737,              0.06477,                  0.5,               1.1779,              0.92074,              0.93902,                  0.2,               4.0594,                    0,              0.01719,              0.67973,               0.3923,                    0,              0.11621,              0.54182,                    0,                    0,                    0,                  0.5,              0.92212,                    0,                    0,               3.1195\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01155, lrf=0.01115, momentum=0.98, weight_decay=0.00054, warmup_epochs=3.62342, warmup_momentum=0.95, warmup_bias_lr=0.15151, box=0.05849, cls=0.46097, cls_pw=1.09443, obj=1.16932, obj_pw=1.20062, iou_t=0.2, anchor_t=4.53724, fl_gamma=0.0, hsv_h=0.01612, hsv_s=0.81168, hsv_v=0.38303, degrees=0.0, translate=0.1026, scale=0.46007, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.2416\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_033240-3m5thbbt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mclear-capybara-283\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3m5thbbt\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.2416\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00054\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 33.8\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.04 anchors/target, 0.013 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7680: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.22: 1.0000 best possible recall, 5.00 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.468/0.768-mean/best, past_thr=0.532-mean: 23,20, 29,39, 42,27, 51,46, 80,71, 177,186\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/9    0.499G    0.1018   0.04924   0.06951         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/9    0.499G    0.0732   0.04451     0.063         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/9    0.499G   0.07237   0.04485   0.05928         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/9    0.501G   0.06856   0.04506   0.05498         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/9    0.501G   0.06384   0.04334   0.05211         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/9    0.501G   0.05926   0.04505   0.04963         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/9    0.501G   0.05586   0.04283   0.04744         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/9    0.501G   0.05476    0.0425   0.04599         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       8/9    0.501G   0.05275   0.04086   0.04333         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       9/9    0.501G    0.0512   0.04015   0.04241         1       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.432      0.392      0.336      0.161\n",
      "\n",
      "10 epochs completed in 0.164 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▄▄▃▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▄▄▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▄▅▅▃▅▃▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▆▃▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▅▇██▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▅▇██▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.33598\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.16116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.4315\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.39244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.33598\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.16116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.4315\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.39244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.04241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.04015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04793\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.03853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mclear-capybara-283\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3m5thbbt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_033240-3m5thbbt/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m23 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m              0.4315,              0.39244,              0.33598,              0.16116,             0.047927,             0.038529,             0.039769,              0.01155,              0.01115,                 0.98,              0.00054,               3.6234,                 0.95,              0.15151,              0.05849,              0.46097,               1.0944,               1.1693,               1.2006,                  0.2,               4.5372,                    0,              0.01612,              0.81168,              0.38303,                    0,               0.1026,              0.46007,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.2416\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0088, lrf=0.01001, momentum=0.97723, weight_decay=0.00047, warmup_epochs=3.02552, warmup_momentum=0.86525, warmup_bias_lr=0.14634, box=0.05438, cls=0.50862, cls_pw=1.18951, obj=0.98448, obj_pw=1.10097, iou_t=0.2, anchor_t=3.69678, fl_gamma=0.0, hsv_h=0.01665, hsv_s=0.68182, hsv_v=0.39146, degrees=0.0, translate=0.11098, scale=0.49878, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.41826\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_034317-vehjuto1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbrisk-silence-284\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/vehjuto1\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "Overriding model.yaml anchors with anchors=2.41826\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00047\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.4GB ram):  48%|████▊     | 531/1105 [00:15<00:17, 31.91\u001b[0m"
     ]
    }
   ],
   "source": [
    "# if training for evolutions, set epochs to 10, and evolve to 50\n",
    "# if you desire to graph the evolution with the hyperparaters, add the --hyp path and change the hyperparameter.yaml file located in opt/ml/input/data/hyp.scratch-low.yaml\n",
    "!export WANDB_RUN_GROUP=\"evolution_const_seed\" && python ./deepsea-yolov5/yolov5/train.py \\\n",
    "--img=640 \\\n",
    "--data=./deepsea-yolov5/opt/ml/custom_config.yaml  \\\n",
    "--batch=2 \\\n",
    "--weights=yolov5s.pt \\\n",
    "--cfg=./deepsea-yolov5/yolov5/models/yolov5s.yaml \\\n",
    "--project=\"902005-vaa\"\\\n",
    "--cache \\\n",
    "--epochs=10 \\\n",
    "--evolve=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Train Using Current Hyperparameter File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanuelgozzi\u001b[0m (\u001b[33mmbari\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=./deepsea-yolov5/yolov5/models/yolov5s.yaml, data=./deepsea-yolov5/opt/ml/custom_config.yaml, hyp=./deepsea-yolov5/opt/ml/input/data/hyp.scratch-low.yaml, epochs=17, batch_size=2, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=902005-vaa, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 4 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.1-291-ga84cd02 Python-3.8.10 torch-1.10.2+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, anchors=0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir 902005-vaa', view at http://localhost:6006/\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220714_161605-3cnosyf0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msandy-plant-294\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3cnosyf0\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml nc=80 with nc=17\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "[2022-07-14 16:16:07.520 pytorch-1-10-gpu-py-ml-g4dn-xlarge-bd81d1f288c5d63d0571c57fb0b0:875 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2022-07-14 16:16:07.659 pytorch-1-10-gpu-py-ml-g4dn-xlarge-bd81d1f288c5d63d0571c57fb0b0:875 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.1\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.2GB ram): 100%|██████████| 277/277 [00:08<00:00, 31.90it/\u001b[0m\n",
      "Plotting labels to 902005-vaa/exp14/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.60 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp14\u001b[0m\n",
      "Starting training for 17 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "  0%|          | 0/553 [00:00<?, ?it/s]                                         \n",
      "Traceback (most recent call last):\n",
      "  File \"./deepsea-yolov5/yolov5/train.py\", line 668, in <module>\n",
      "    main(opt)\n",
      "  File \"./deepsea-yolov5/yolov5/train.py\", line 563, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"./deepsea-yolov5/yolov5/train.py\", line 327, in train\n",
      "    for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/tqdm/std.py\", line 1180, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/root/mgozzi-augment/deepsea-yolov5/yolov5/utils/dataloaders.py\", line 158, in __iter__\n",
      "    yield next(self.iterator)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 529, in __next__\n",
      "    (data, worker_id) = self._next_data()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1277, in _next_data\n",
      "    return (self._process_data(data), w_id)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1303, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/_utils.py\", line 434, in reraise\n",
      "    raise exception\n",
      "KeyError: Caught KeyError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 295, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/root/mgozzi-augment/deepsea-yolov5/yolov5/utils/dataloaders.py\", line 592, in __getitem__\n",
      "    img, labels = self.load_mosaic(index)\n",
      "  File \"/root/mgozzi-augment/deepsea-yolov5/yolov5/utils/dataloaders.py\", line 728, in load_mosaic\n",
      "    img4, labels4, segments4 = copy_paste(img4, labels4, segments4, p=self.hyp['copy_paste'])\n",
      "KeyError: 'copy_paste'\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msandy-plant-294\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3cnosyf0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220714_161605-3cnosyf0/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Change the contents of the deeosea-yolov5/opt/ml/input/data/hyp.scratch-low.yaml \n",
    "# to utilize the best found hyperparameters from the evolutions performed above. \n",
    "!export WANDB_RUN_GROUP=\"hyperparam_const_seed\" && python ./deepsea-yolov5/yolov5/train.py \\\n",
    "--img=640 \\\n",
    "--data=./deepsea-yolov5/opt/ml/custom_config.yaml  \\\n",
    "--batch=2 \\\n",
    "--weights=yolov5s.pt \\\n",
    "--cfg=./deepsea-yolov5/yolov5/models/yolov5s.yaml \\\n",
    "--hyp=./deepsea-yolov5/opt/ml/input/data/hyp.scratch-low.yaml \\\n",
    "--project=\"902005-vaa\"\\\n",
    "--cache \\\n",
    "--epochs=17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a sweep (doesn't work well yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "\n",
    "import os\n",
    "os.environ['WANDB_PROJECT']=\"902005-vaa\"\n",
    "\n",
    "!wandb sweep deepsea-yolov5/yolov5/utils/loggers/wandb/sweep.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace mbari/.../... with output from command above\n",
    "!wandb agent mbari/902005-vaa/w8krnvak"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.10-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "10473cd72beb9f903a0df0895b8cbe75ad84c2c6b795c916562cda13d35a2cb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
