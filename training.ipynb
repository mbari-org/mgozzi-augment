{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Deepsea Network\n",
    "This project incorporates wandb directly inside the YOLOv5 network (wandb support was added by ultralytics). This notebook allows us to retrain the model and see how train time augmentations can improve the networks ability to detect and track objects without increasing the data sample size. \n",
    "\n",
    "## Notes\n",
    "Training using the ml.p3.2xlarge is about 10x faster ml.t3.medium which makes the p3 more cost effective. \n",
    "\n",
    "## Known Issues\n",
    "When running the training script in quick succession on the g4dn.xlarge, a memory issue may arise. Shut down the running instance and wait for the machine to become available again and restart the program. This seems to be an issue related to YOLOv5 and Sagemaker's use of a RAM partition as \"storage.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.2.2 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 5)) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 6)) (1.22.2)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 7)) (4.5.5.62)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 8)) (9.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 9)) (5.4.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 10)) (2.27.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 11)) (1.8.0)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 12)) (1.10.2+cu113)\n",
      "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 13)) (0.11.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 14)) (4.62.3)\n",
      "Requirement already satisfied: protobuf<4.21.3 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 15)) (3.19.4)\n",
      "Collecting tensorboard>=2.4.1\n",
      "  Using cached tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 22)) (1.4.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 23)) (0.11.2)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 35)) (8.0.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from -r deepsea-yolov5/yolov5/requirements.txt (line 36)) (5.9.0)\n",
      "Collecting thop\n",
      "  Using cached thop-0.1.1.post2207130030-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r deepsea-yolov5/yolov5/requirements.txt (line 5)) (4.29.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r deepsea-yolov5/yolov5/requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r deepsea-yolov5/yolov5/requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r deepsea-yolov5/yolov5/requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r deepsea-yolov5/yolov5/requirements.txt (line 5)) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r deepsea-yolov5/yolov5/requirements.txt (line 5)) (3.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.23.0->-r deepsea-yolov5/yolov5/requirements.txt (line 10)) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.23.0->-r deepsea-yolov5/yolov5/requirements.txt (line 10)) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.23.0->-r deepsea-yolov5/yolov5/requirements.txt (line 10)) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.23.0->-r deepsea-yolov5/yolov5/requirements.txt (line 10)) (1.26.7)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r deepsea-yolov5/yolov5/requirements.txt (line 12)) (4.1.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (0.37.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (2.0.3)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.47.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (60.9.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.1.4->-r deepsea-yolov5/yolov5/requirements.txt (line 22)) (2021.3)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.7.5)\n",
      "Requirement already satisfied: black in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (22.1.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.1.3)\n",
      "Requirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (5.1.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.2.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (2.12.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (3.0.29)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (4.7.2)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (4.11.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.2.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (8.0.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.8/site-packages (from black->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.4.3)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.9.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (2.0.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.8/site-packages (from black->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (2.5.1)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.2.2)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython->-r deepsea-yolov5/yolov5/requirements.txt (line 35)) (0.8.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r deepsea-yolov5/yolov5/requirements.txt (line 18)) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, tensorboard-data-server, pyasn1-modules, oauthlib, grpcio, cachetools, absl-py, thop, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard\n",
      "Successfully installed absl-py-1.2.0 cachetools-5.2.0 google-auth-2.9.1 google-auth-oauthlib-0.4.6 grpcio-1.47.0 markdown-3.4.1 oauthlib-3.2.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 thop-0.1.1.post2207130030\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting wandb\n",
      "  Using cached wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from wandb) (60.9.3)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.16.0)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Using cached shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.9.0)\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Using cached GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (8.0.4)\n",
      "Collecting promise<3,>=2.0\n",
      "  Using cached promise-2.3-py3-none-any.whl\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb) (5.4.1)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting pathtools\n",
      "  Using cached pathtools-0.1.2-py3-none-any.whl\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.19.4)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Using cached sentry_sdk-1.8.0-py2.py3-none-any.whl (153 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.27.1)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pathtools, smmap, shortuuid, setproctitle, sentry-sdk, promise, docker-pycreds, gitdb, GitPython, wandb\n",
      "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 promise-2.3 sentry-sdk-1.8.0 setproctitle-1.3.0 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.21\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanuelgozzi\u001b[0m (\u001b[33mmbari\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!pip install -r deepsea-yolov5/yolov5/requirements.txt\n",
    "!pip install wandb\n",
    "!wandb login # append wandb login key here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training For Evolutions\n",
    "This will train the network and output the results of the generations to wandb. The best generation will be saved to data/hyps folder under the YOLOv5 directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanuelgozzi\u001b[0m (\u001b[33mmbari\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=deepsea-yolov5/yolov5/yolov5s.pt, cfg=./deepsea-yolov5/yolov5/models/yolov5s.yaml, data=./deepsea-yolov5/opt/ml/custom_config.yaml, hyp=deepsea-yolov5/yolov5/data/hyps/hyp.scratch-low.yaml, epochs=25, batch_size=2, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=35, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=902005-vaa, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "remote: Enumerating objects: 19, done.\u001b[K\n",
      "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
      "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
      "remote: Total 19 (delta 8), reused 14 (delta 7), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (19/19), 25.98 KiB | 51.00 KiB/s, done.\n",
      "From https://github.com/ultralytics/yolov5\n",
      "   fabac7c..1038734  classifier             -> origin/classifier\n",
      " * [new branch]      fix/rgb_albumentations -> origin/fix/rgb_albumentations\n",
      "   d5116bb..3e85863  master                 -> origin/master\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 34 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.1-291-ga84cd02 Python-3.8.10 torch-1.10.2+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_172303-3ur33q2i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmorning-spaceship-488\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3ur33q2i\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=3\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "[2022-07-27 17:23:06.476 pytorch-1-10-gpu-py-ml-g4dn-xlarge-bd81d1f288c5d63d0571c57fb0b0:155 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2022-07-27 17:23:06.603 pytorch-1-10-gpu-py-ml-g4dn-xlarge-bd81d1f288c5d63d0571c57fb0b0:155 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:47<00:00, 23.2\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.16 anchors/target, 0.045 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 6.95 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.529-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.508G    0.1027   0.03647    0.0747         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.508G   0.07416     0.034    0.0673         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.508G   0.06751   0.03156   0.06382         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24     0.51G   0.06096   0.03015   0.06145        17       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24     0.51G    0.0551   0.03005    0.0583         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24     0.51G   0.05189   0.03018   0.05414         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24     0.51G   0.04778   0.02874   0.05005         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24     0.51G   0.04934    0.0284   0.04789         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24     0.51G   0.04754   0.02924   0.04365         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24     0.51G   0.04565    0.0286   0.03909         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24     0.51G   0.04556   0.02729    0.0356         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24     0.51G   0.04459   0.02717   0.03352         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24     0.51G   0.04208   0.02583   0.03099         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24     0.51G   0.04286   0.02696   0.02876         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24     0.51G   0.04295   0.02568   0.02718         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24     0.51G   0.04145   0.02582   0.02514         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24     0.51G    0.0413   0.02703   0.02274         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24     0.51G   0.04022   0.02475   0.02081         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24     0.51G   0.03862   0.02488   0.01924         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24     0.51G   0.03883   0.02411   0.01768         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24     0.51G   0.03823   0.02521   0.01752         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24     0.51G   0.03644   0.02403    0.0161         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24     0.51G   0.03503   0.02381   0.01527         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24     0.51G   0.03459   0.02395   0.01479         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24     0.51G   0.03436   0.02323   0.01357        36       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.752      0.707      0.739      0.439\n",
      "\n",
      "25 epochs completed in 0.385 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▇▅▅▅▅▄▄▄▄▃▃▂▃▂▂▃▂▂▁▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.73891\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.43886\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.75171\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.70746\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.73891\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.43886\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.75171\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.70746\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01357\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmorning-spaceship-488\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3ur33q2i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_172303-3ur33q2i/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m1 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.75171,              0.70746,              0.73891,              0.43886,             0.033724,             0.022069,             0.012229,                 0.01,                 0.01,                0.937,               0.0005,                    3,                  0.8,                  0.1,                 0.05,                  0.5,                    1,                    1,                    1,                  0.2,                    4,                    0,                0.015,                  0.7,                  0.4,                    0,                  0.1,                  0.5,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                    3\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01031, momentum=0.9799, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.74923, warmup_bias_lr=0.1, box=0.05301, cls=0.49268, cls_pw=1.06327, obj=0.88846, obj_pw=1.22737, iou_t=0.2, anchor_t=4.37657, fl_gamma=0.0, hsv_h=0.01509, hsv_s=0.72535, hsv_v=0.41833, degrees=0.0, translate=0.10982, scale=0.41905, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.98022\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_174719-23lw9p9x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mancient-sea-489\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/23lw9p9x\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=2.98022\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:35<00:00, 31.1\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.20 anchors/target, 0.053 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 7.18 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.520-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24     0.51G     0.111   0.03798   0.07765         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24     0.51G   0.07991   0.03595   0.06962         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24     0.51G   0.07429   0.03316   0.06561         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24     0.51G   0.06361    0.0327   0.06227        17       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24     0.51G   0.05659   0.03273   0.05866         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24     0.51G   0.05371    0.0331   0.05549         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24     0.51G   0.05243   0.03242   0.05259         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24     0.51G   0.05098   0.03181   0.05101         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24     0.51G   0.05096   0.03303   0.04744         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24     0.51G    0.0487   0.03215    0.0447         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24     0.51G    0.0478   0.03092   0.04173         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24     0.51G   0.04872   0.03071   0.03955         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24     0.51G   0.04604   0.02956   0.03747         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24     0.51G   0.04632   0.03065   0.03472         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24     0.51G   0.04598   0.02913   0.03327         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24     0.51G   0.04454   0.02915   0.03155         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24     0.51G   0.04496   0.03029   0.02952         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24     0.51G   0.04389   0.02795   0.02777         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24     0.51G   0.04273   0.02785   0.02703         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24     0.51G   0.04243     0.027   0.02542         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24     0.51G   0.04238   0.02785   0.02457         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24     0.51G   0.04071    0.0268   0.02285         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24     0.51G   0.04006   0.02691   0.02192         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.512G   0.03905   0.02668   0.02183         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.512G   0.03917   0.02618   0.02067        29       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.673      0.595      0.639      0.357\n",
      "\n",
      "25 epochs completed in 0.384 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▇▅▅▅▅▅▄▅▅▄▄▃▄▃▃▃▂▂▁▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.63932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.35738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.67294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.59456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.63932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.35738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.67294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.59456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03917\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02618\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mancient-sea-489\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/23lw9p9x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_174719-23lw9p9x/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m2 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.67294,              0.59456,              0.63932,              0.35738,             0.038602,             0.024915,              0.01967,                 0.01,              0.01031,               0.9799,               0.0005,                    3,              0.74923,                  0.1,              0.05301,              0.49268,               1.0633,              0.88846,               1.2274,                  0.2,               4.3766,                    0,              0.01509,              0.72535,              0.41833,                    0,              0.10982,              0.41905,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.9802\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00676, lrf=0.01, momentum=0.92501, weight_decay=0.00045, warmup_epochs=3.05712, warmup_momentum=0.90502, warmup_bias_lr=0.11944, box=0.05176, cls=0.5398, cls_pw=0.97145, obj=1.18456, obj_pw=0.93089, iou_t=0.2, anchor_t=3.40104, fl_gamma=0.0, hsv_h=0.01267, hsv_s=0.47168, hsv_v=0.30328, degrees=0.0, translate=0.10739, scale=0.46468, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3.0\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_181110-vvdoj49d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msuper-wood-490\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/vvdoj49d\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=3.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00045\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.0\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.11 anchors/target, 0.032 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8029: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.29: 1.0000 best possible recall, 6.44 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.447/0.803-mean/best, past_thr=0.552-mean: 17,15, 26,25, 43,27, 32,42, 53,42, 48,69, 79,64, 120,104, 216,258\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.503G       0.1   0.03882   0.07791         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.503G   0.06894   0.03584   0.07019         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.503G    0.0657   0.03226   0.06686         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.503G   0.06079   0.03057   0.06439        17       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.503G   0.05424   0.02994   0.06109         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.503G    0.0509   0.03075   0.05696         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.503G   0.04808   0.02941   0.05317         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.503G   0.04797   0.02861   0.05129         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.503G    0.0465   0.02992   0.04739         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.503G   0.04528   0.02922   0.04361         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.503G   0.04478   0.02762   0.03879         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.503G   0.04429   0.02785   0.03634         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.503G   0.04393   0.02625   0.03359         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.503G   0.04159    0.0273   0.03075         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.503G   0.04293   0.02599   0.02825         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.503G   0.04153   0.02602   0.02691         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.503G   0.04132   0.02756   0.02447         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.503G   0.03999   0.02518   0.02246         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.503G   0.03809   0.02544   0.02171         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.503G   0.03747   0.02444   0.01914         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.503G   0.03776   0.02545   0.01911         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.503G   0.03657   0.02428   0.01763         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.503G   0.03492   0.02434   0.01673         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.505G   0.03475   0.02457   0.01613         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.505G   0.03445    0.0239   0.01538        32       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.765      0.665       0.72      0.423\n",
      "\n",
      "25 epochs completed in 0.382 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▇▅▄▄▄▄▃▄▃▃▃▂▃▂▂▃▂▂▁▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.71968\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.42283\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.76521\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.66515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.71968\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.42283\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.76521\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.66515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.0239\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01667\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msuper-wood-490\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/vvdoj49d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_181110-vvdoj49d/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m3 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.76521,              0.66515,              0.71968,              0.42283,             0.035462,             0.023612,             0.016667,              0.00676,                 0.01,              0.92501,              0.00045,               3.0571,              0.90502,              0.11944,              0.05176,               0.5398,              0.97145,               1.1846,              0.93089,                  0.2,                3.401,                    0,              0.01267,              0.47168,              0.30328,                    0,              0.10739,              0.46468,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                    3\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00623, lrf=0.01, momentum=0.91352, weight_decay=0.00045, warmup_epochs=2.64547, warmup_momentum=0.90502, warmup_bias_lr=0.12479, box=0.0472, cls=0.53383, cls_pw=0.97145, obj=1.28651, obj_pw=1.0193, iou_t=0.2, anchor_t=3.39657, fl_gamma=0.0, hsv_h=0.01101, hsv_s=0.41435, hsv_v=0.32358, degrees=0.0, translate=0.11118, scale=0.51175, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.97255, mixup=0.0, copy_paste=0.0, anchors=3.98471\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_183450-2y93kky2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mplayful-dew-491\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2y93kky2\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=3.98471\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     79112  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7085256 parameters, 7085256 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00045\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.4\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.35 anchors/target, 0.081 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 12 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8237: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.29: 1.0000 best possible recall, 8.33 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=12, img_size=640, metric_all=0.438/0.824-mean/best, past_thr=0.551-mean: 16,14, 27,22, 23,34, 37,36, 49,28, 37,52, 57,45, 58,70, 82,62, 116,99, 193,125, 289,266\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.501G   0.09434   0.04423   0.07708         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.501G   0.06612    0.0389   0.07086         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.503G   0.06061   0.03538   0.06705         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.503G   0.05551    0.0348   0.06529         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.503G   0.04973   0.03436   0.06271         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.503G    0.0461   0.03324   0.05937         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.503G   0.04254   0.03259   0.05738         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.503G   0.04307   0.03219   0.05458         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.503G   0.04179   0.03212   0.05338         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.503G   0.04072   0.03038   0.05128         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.503G   0.03914   0.02832   0.04923         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.503G   0.04122    0.0307   0.04693         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.503G   0.03887   0.02971   0.04457         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.503G   0.03748   0.02921   0.04288         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.503G   0.03754   0.03049   0.04065         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.503G   0.03697   0.02932   0.03927         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.503G   0.03655   0.02875   0.03692         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.503G    0.0357   0.02918   0.03526         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.503G   0.03508   0.02855   0.03381         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.503G   0.03438   0.02795   0.03232         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.503G   0.03354   0.02715   0.03093         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.503G   0.03307   0.02778   0.03018         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.503G   0.03206   0.02688   0.02934         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.503G     0.032   0.02816   0.02739         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.503G   0.03223   0.02821   0.02813         1       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.658      0.535      0.585      0.336\n",
      "\n",
      "25 epochs completed in 0.391 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▆▄▄▄▄▃▃▃▂▂▃▂▂▂▂▂▂▂▁▁▁▁▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.58476\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.33615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.65849\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.5354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.58476\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.33615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.65849\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.5354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02821\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mplayful-dew-491\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2y93kky2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_183450-2y93kky2/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m4 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.65849,               0.5354,              0.58476,              0.33615,              0.03168,             0.026318,             0.028948,              0.00623,                 0.01,              0.91352,              0.00045,               2.6455,              0.90502,              0.12479,               0.0472,              0.53383,              0.97145,               1.2865,               1.0193,                  0.2,               3.3966,                    0,              0.01101,              0.41435,              0.32358,                    0,              0.11118,              0.51175,                    0,                    0,                    0,                  0.5,              0.97255,                    0,                    0,               3.9847\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0101, lrf=0.01, momentum=0.98, weight_decay=0.00053, warmup_epochs=3.28707, warmup_momentum=0.68598, warmup_bias_lr=0.06166, box=0.04444, cls=0.49268, cls_pw=1.06585, obj=0.6963, obj_pw=1.2274, iou_t=0.2, anchor_t=4.62468, fl_gamma=0.0, hsv_h=0.01704, hsv_s=0.72535, hsv_v=0.38324, degrees=0.0, translate=0.10723, scale=0.43647, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=4.26676\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_185903-jmb4k7b0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meffortless-brook-492\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/jmb4k7b0\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=4.26676\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     79112  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7085256 parameters, 7085256 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00053\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 33.9\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.85 anchors/target, 0.207 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 12 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8237: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.22: 1.0000 best possible recall, 9.63 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=12, img_size=640, metric_all=0.438/0.824-mean/best, past_thr=0.512-mean: 16,14, 27,22, 23,34, 37,36, 49,28, 37,52, 57,45, 58,70, 82,62, 116,99, 193,125, 289,266\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.499G    0.1007   0.03107   0.07887         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.499G   0.06967    0.0327   0.07245         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.501G   0.06325   0.02654   0.06749         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.501G     0.057   0.02743   0.06373         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.501G   0.04917   0.02667   0.05966         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.501G   0.04545   0.02606   0.05588         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.501G   0.04438     0.026   0.05364         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.501G   0.04174   0.02581   0.04926         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.501G   0.04153   0.02603   0.04793         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.501G   0.04112   0.02512   0.04454         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.501G   0.03974   0.02385    0.0419         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.501G   0.04023   0.02374   0.03755         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.501G   0.03931   0.02344   0.03591         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.501G   0.03879   0.02291   0.03452         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.501G   0.03812   0.02356   0.03126         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.501G   0.03722   0.02338   0.02951         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.501G   0.03735   0.02229   0.02797         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.501G   0.03627    0.0232   0.02512         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.501G   0.03583   0.02167   0.02355         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.501G    0.0348   0.02109    0.0231         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.501G   0.03468   0.02109   0.02134         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.501G   0.03421   0.02045   0.01977         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.501G   0.03422   0.02162   0.01826         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.501G   0.03319   0.02131   0.01735         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.501G   0.03269   0.02144   0.01722         4       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616       0.68       0.69      0.691      0.384\n",
      "\n",
      "25 epochs completed in 0.401 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▇█▄▅▅▄▄▄▄▄▃▃▃▂▃▃▂▃▂▁▁▁▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▆▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▅████▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▅████▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.69076\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.38446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.68008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.68985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.69076\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.38446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.68008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.68985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03269\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01722\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01577\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01957\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33meffortless-brook-492\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/jmb4k7b0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_185903-jmb4k7b0/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m5 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.68008,              0.68985,              0.69076,              0.38446,             0.032094,             0.019567,             0.015767,               0.0101,                 0.01,                 0.98,              0.00053,               3.2871,              0.68598,              0.06166,              0.04444,              0.49268,               1.0658,               0.6963,               1.2274,                  0.2,               4.6247,                    0,              0.01704,              0.72535,              0.38324,                    0,              0.10723,              0.43647,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               4.2668\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00956, lrf=0.0134, momentum=0.98, weight_decay=0.00045, warmup_epochs=2.52721, warmup_momentum=0.69931, warmup_bias_lr=0.12212, box=0.05301, cls=0.47832, cls_pw=1.00099, obj=0.99534, obj_pw=0.89147, iou_t=0.2, anchor_t=4.30856, fl_gamma=0.0, hsv_h=0.01446, hsv_s=0.74896, hsv_v=0.50156, degrees=0.0, translate=0.10768, scale=0.36601, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.97651, mixup=0.0, copy_paste=0.0, anchors=2.63906\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_192355-79m8cbz8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcosmic-surf-493\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/79m8cbz8\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=2.63906\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00045\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 34.0\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.19 anchors/target, 0.050 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 7.15 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.522-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.501G      0.11    0.0346   0.07165         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.501G   0.08038    0.0324   0.06471         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.501G   0.07123   0.03005   0.06214         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.501G   0.05991   0.03027   0.05924        26       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.501G    0.0547   0.02831   0.05592         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.501G   0.05375    0.0292   0.05382         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.501G   0.05094   0.02822   0.05135         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.501G   0.04875   0.02786    0.0492         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.501G   0.04936   0.02843     0.048         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.501G    0.0483   0.02797   0.04549         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.501G    0.0477   0.02821   0.04361         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.501G   0.04692   0.02818   0.04031         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.501G   0.04519   0.02624   0.03798         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.501G   0.04505   0.02557   0.03536         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.501G   0.04409   0.02625   0.03367         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.501G   0.04386   0.02593   0.03247         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.501G   0.04333   0.02653   0.03141         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.501G   0.04322   0.02501   0.02873         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.501G   0.04153   0.02518   0.02765         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.501G    0.0432   0.02586   0.02601         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.501G   0.04112   0.02505   0.02458         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.501G   0.04024   0.02391   0.02302         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.501G   0.04065   0.02482   0.02208        23       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.501G   0.03925   0.02482   0.02156         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.501G   0.03854   0.02359   0.02012        12       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616       0.64      0.606      0.624      0.355\n",
      "\n",
      "25 epochs completed in 0.399 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▇▅▅▄▅▄▄▄▄▄▄▃▂▃▂▃▂▂▂▂▁▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▄▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▄▇███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▄▇███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.62353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.35469\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.64046\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.6055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.62353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.35469\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.64046\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.6055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03854\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02033\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mcosmic-surf-493\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/79m8cbz8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_192355-79m8cbz8/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m6 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.64046,               0.6055,              0.62353,              0.35469,             0.038605,             0.022761,             0.020328,              0.00956,               0.0134,                 0.98,              0.00045,               2.5272,              0.69931,              0.12212,              0.05301,              0.47832,                1.001,              0.99534,              0.89147,                  0.2,               4.3086,                    0,              0.01446,              0.74896,              0.50156,                    0,              0.10768,              0.36601,                    0,                    0,                    0,                  0.5,              0.97651,                    0,                    0,               2.6391\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0102, lrf=0.01005, momentum=0.98, weight_decay=0.00057, warmup_epochs=3.34564, warmup_momentum=0.73635, warmup_bias_lr=0.0621, box=0.04444, cls=0.52411, cls_pw=1.04349, obj=0.64866, obj_pw=1.14354, iou_t=0.2, anchor_t=4.40328, fl_gamma=0.0, hsv_h=0.01833, hsv_s=0.65997, hsv_v=0.35835, degrees=0.0, translate=0.10562, scale=0.45003, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.98067, mixup=0.0, copy_paste=0.0, anchors=3.51916\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_194838-3arsfv8p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mclear-terrain-494\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3arsfv8p\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=3.51916\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     79112  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7085256 parameters, 7085256 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00057\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 33.8\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.74 anchors/target, 0.179 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 12 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8237: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 9.45 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=12, img_size=640, metric_all=0.438/0.824-mean/best, past_thr=0.517-mean: 16,14, 27,22, 23,34, 37,36, 49,28, 37,52, 57,45, 58,70, 82,62, 116,99, 193,125, 289,266\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.499G   0.09869   0.02767   0.08211         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.499G   0.06563   0.02901   0.07501         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.499G   0.06099   0.02439   0.07036         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.499G   0.05751   0.02301   0.06571         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.499G   0.04955   0.02304   0.06116         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.499G   0.04412   0.02297    0.0581         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.499G    0.0429   0.02222   0.05497         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.499G   0.04284   0.02241   0.05252         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.499G   0.04121   0.02244   0.04934         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.499G   0.04081   0.02122   0.04485         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.499G   0.04049   0.02078   0.04206         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.499G   0.04013   0.02182   0.03836         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.499G   0.04047   0.02046   0.03585         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.499G   0.03911   0.02049   0.03356        10       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.499G   0.03802   0.02042   0.03192         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.499G   0.03856   0.02078   0.02944         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.499G   0.03716   0.01948   0.02833         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.499G   0.03716   0.02035   0.02499         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.499G   0.03649   0.01974    0.0243         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.499G   0.03539   0.01948   0.02219         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.499G   0.03458   0.01797   0.02005         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.499G   0.03467   0.01891   0.01986         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.499G   0.03423   0.01867   0.01903         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.499G   0.03296   0.01897    0.0174         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.499G    0.0329   0.01861   0.01641         3       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.691      0.625      0.671      0.369\n",
      "\n",
      "25 epochs completed in 0.402 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▄▄▄▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▅▅▅▅▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▇█▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▁▂▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▆▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▅████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▅████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.67123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.36867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.69116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.62482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.67123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.36867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.69116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.62482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0329\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00091\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00091\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00091\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mclear-terrain-494\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3arsfv8p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_194838-3arsfv8p/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m7 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.69116,              0.62482,              0.67123,              0.36867,             0.032302,             0.017539,             0.017681,               0.0102,              0.01005,                 0.98,              0.00057,               3.3456,              0.73635,               0.0621,              0.04444,              0.52411,               1.0435,              0.64866,               1.1435,                  0.2,               4.4033,                    0,              0.01833,              0.65997,              0.35835,                    0,              0.10562,              0.45003,                    0,                    0,                    0,                  0.5,              0.98067,                    0,                    0,               3.5192\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0097, lrf=0.01, momentum=0.98, weight_decay=0.00057, warmup_epochs=3.24694, warmup_momentum=0.73595, warmup_bias_lr=0.05999, box=0.04444, cls=0.51652, cls_pw=1.0435, obj=0.66803, obj_pw=1.1435, iou_t=0.2, anchor_t=4.4033, fl_gamma=0.0, hsv_h=0.01833, hsv_s=0.65997, hsv_v=0.38262, degrees=0.0, translate=0.10337, scale=0.45472, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.98067, mixup=0.0, copy_paste=0.0, anchors=3.35854\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_201333-2eb77l55\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdevoted-jazz-495\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2eb77l55\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=3.35854\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00057\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:33<00:00, 33.4\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.20 anchors/target, 0.054 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 7.20 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.519-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.501G    0.0967   0.02768   0.08076         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.501G   0.06709   0.02715   0.07203         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.501G     0.062   0.02474   0.06777         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.501G   0.05685   0.02334   0.06212         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.501G   0.04869    0.0234   0.05706         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.501G    0.0469   0.02417   0.05353         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.503G   0.04486   0.02237   0.04844         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.503G   0.04311   0.02227   0.04526         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.503G   0.04272   0.02318   0.04128         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.503G   0.04182   0.02324   0.03778         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.503G   0.04217   0.02249   0.03486         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.503G   0.04117   0.02224   0.03313         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.503G    0.0401    0.0216   0.03003         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.503G   0.03998   0.02112   0.02835         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.503G   0.03928   0.02117   0.02559         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.503G   0.03833   0.02111   0.02396         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.503G   0.03807   0.02182   0.02141         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.503G   0.03789   0.02024   0.02027         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.503G   0.03668   0.02077   0.01963         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.503G   0.03685   0.01979    0.0176         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.503G   0.03561   0.02061   0.01718         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.503G   0.03553   0.01927   0.01513         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.503G   0.03501   0.01909   0.01589         4       640:  35%|███\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n",
      "     22/24    0.503G   0.03528    0.0199    0.0161         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.503G    0.0337   0.01981    0.0146         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.503G   0.03268   0.01914   0.01364         2       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.763      0.664      0.714      0.407\n",
      "\n",
      "25 epochs completed in 0.405 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ██▆▄▄▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▅████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▅████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.71436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.40681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.7627\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.66421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.71436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.40681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.7627\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.66421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03268\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01914\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.0178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdevoted-jazz-495\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2eb77l55\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_201333-2eb77l55/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m8 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m              0.7627,              0.66421,              0.71436,              0.40681,             0.031868,             0.017804,             0.014253,               0.0097,                 0.01,                 0.98,              0.00057,               3.2469,              0.73595,              0.05999,              0.04444,              0.51652,               1.0435,              0.66803,               1.1435,                  0.2,               4.4033,                    0,              0.01833,              0.65997,              0.38262,                    0,              0.10337,              0.45472,                    0,                    0,                    0,                  0.5,              0.98067,                    0,                    0,               3.3585\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01012, lrf=0.01004, momentum=0.97964, weight_decay=0.00053, warmup_epochs=3.2871, warmup_momentum=0.68619, warmup_bias_lr=0.06168, box=0.04408, cls=0.48969, cls_pw=1.0658, obj=0.69964, obj_pw=1.2259, iou_t=0.2, anchor_t=4.65289, fl_gamma=0.0, hsv_h=0.01702, hsv_s=0.73279, hsv_v=0.38208, degrees=0.0, translate=0.10771, scale=0.43852, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.99764, mixup=0.0, copy_paste=0.0, anchors=4.31487\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_203837-ostgt3ax\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwise-fog-496\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/ostgt3ax\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=4.31487\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     79112  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7085256 parameters, 7085256 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00053\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 33.6\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.87 anchors/target, 0.211 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 12 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8237: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.21: 1.0000 best possible recall, 9.65 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=12, img_size=640, metric_all=0.438/0.824-mean/best, past_thr=0.511-mean: 16,14, 27,22, 23,34, 37,36, 49,28, 37,52, 57,45, 58,70, 82,62, 116,99, 193,125, 289,266\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.499G    0.1004   0.03095   0.07849         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.499G   0.06907   0.03201   0.07174         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.501G   0.06291   0.02666   0.06708         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.501G   0.05631   0.02818   0.06387         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.501G   0.04908   0.02666   0.05962        10       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.501G   0.04462   0.02639    0.0551         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.501G    0.0429   0.02612   0.05393         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.501G   0.04275   0.02548   0.04931         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.501G   0.04158    0.0256    0.0472         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.501G   0.04034   0.02484   0.04363         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.501G   0.04005   0.02361   0.04112         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.501G   0.03974   0.02351   0.03707         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.501G   0.03985   0.02383   0.03549         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.501G   0.03916   0.02322   0.03372         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.501G   0.03858   0.02349   0.03056         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.501G    0.0376   0.02324   0.02872         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.501G   0.03744   0.02251   0.02629         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.501G   0.03633    0.0231   0.02355         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.501G    0.0355   0.02154   0.02235         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.501G    0.0357   0.02127    0.0216        15       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.501G    0.0345   0.02097   0.02084         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.501G   0.03394   0.02087   0.01896         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.501G   0.03379   0.02217   0.01748         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.501G   0.03304   0.02085   0.01732         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.501G    0.0329   0.02192    0.0176         8       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.714       0.61      0.673      0.367\n",
      "\n",
      "25 epochs completed in 0.408 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▇█▅▆▅▄▄▄▄▄▃▃▃▂▃▃▂▂▁▁▁▁▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▆▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▅████▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▅████▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.6727\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.36708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.71353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.61015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.6727\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.36708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.71353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.61015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0329\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03269\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01654\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mwise-fog-496\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/ostgt3ax\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_203837-ostgt3ax/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m9 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.71353,              0.61015,               0.6727,              0.36708,             0.032691,             0.019914,             0.016543,              0.01012,              0.01004,              0.97964,              0.00053,               3.2871,              0.68619,              0.06168,              0.04408,              0.48969,               1.0658,              0.69964,               1.2259,                  0.2,               4.6529,                    0,              0.01702,              0.73279,              0.38208,                    0,              0.10771,              0.43852,                    0,                    0,                    0,                  0.5,              0.99764,                    0,                    0,               4.3149\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00769, lrf=0.01049, momentum=0.98, weight_decay=0.00051, warmup_epochs=2.93409, warmup_momentum=0.78963, warmup_bias_lr=0.05785, box=0.04633, cls=0.55609, cls_pw=1.09961, obj=0.6963, obj_pw=1.2274, iou_t=0.2, anchor_t=4.65498, fl_gamma=0.0, hsv_h=0.01704, hsv_s=0.79364, hsv_v=0.33678, degrees=0.0, translate=0.09883, scale=0.43647, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.84953, mixup=0.0, copy_paste=0.0, anchors=4.89302\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_210354-3dbv9n06\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdry-feather-497\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3dbv9n06\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=4.89302\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     98890  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7105034 parameters, 7105034 gradients, 16.2 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00051\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 33.5\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.10 anchors/target, 0.409 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 15 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8370: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.21: 1.0000 best possible recall, 11.40 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=15, img_size=640, metric_all=0.414/0.837-mean/best, past_thr=0.504-mean: 14,13, 24,20, 23,34, 32,24, 35,37, 50,29, 37,55, 55,44, 73,56, 61,74, 106,79, 113,120, 203,109, 206,257, 475,277\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.501G    0.1004   0.03001   0.09111         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.501G   0.06934   0.03083   0.08209        22       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.501G   0.06351   0.02568   0.07762         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.501G   0.05492   0.02461   0.07393         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.501G   0.04801   0.02344   0.07019         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.501G   0.04566   0.02406   0.06705        20       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.501G   0.04379   0.02404   0.06454         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.501G   0.04331   0.02248    0.0625         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.501G   0.04252   0.02291    0.0606         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.501G   0.04148   0.02272   0.05712         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.501G   0.04096   0.02117   0.05429         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.501G   0.04067   0.02261   0.05236         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.501G   0.04036   0.02118   0.04852         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.501G   0.03973   0.02138   0.04531         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.501G   0.03973   0.02096   0.04222         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.501G   0.03876   0.02058   0.03975         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.501G   0.03865   0.02076   0.03676         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.501G   0.03783   0.02069   0.03469         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.501G   0.03801   0.01975   0.03328         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.501G   0.03776   0.02029   0.03055         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.501G   0.03621   0.02016   0.02989         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.501G   0.03603   0.01942   0.02631         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.501G   0.03562   0.02051   0.02575        10       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.501G   0.03533   0.02047   0.02393         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.501G   0.03417   0.01858   0.02322         0       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.667      0.583      0.636      0.354\n",
      "\n",
      "25 epochs completed in 0.410 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ██▅▄▄▄▄▃▃▃▂▃▂▃▂▂▂▂▂▂▂▁▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.63572\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.35392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.66676\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.58323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.63572\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.35392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.66676\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.58323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02322\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01858\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdry-feather-497\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3dbv9n06\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_210354-3dbv9n06/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m10 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.66676,              0.58323,              0.63572,              0.35392,             0.033982,             0.019715,             0.022892,              0.00769,              0.01049,                 0.98,              0.00051,               2.9341,              0.78963,              0.05785,              0.04633,              0.55609,               1.0996,               0.6963,               1.2274,                  0.2,                4.655,                    0,              0.01704,              0.79364,              0.33678,                    0,              0.09883,              0.43647,                    0,                    0,                    0,                  0.5,              0.84953,                    0,                    0,                4.893\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01051, lrf=0.01271, momentum=0.98, weight_decay=0.00039, warmup_epochs=3.2871, warmup_momentum=0.82682, warmup_bias_lr=0.07301, box=0.03529, cls=0.47461, cls_pw=0.98422, obj=0.87173, obj_pw=1.152, iou_t=0.2, anchor_t=5.64605, fl_gamma=0.0, hsv_h=0.01641, hsv_s=0.67406, hsv_v=0.35862, degrees=0.0, translate=0.10723, scale=0.50993, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=5.61375\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_212918-23j84b2r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwoven-planet-498\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/23j84b2r\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=5.61375\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1    118668  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7124812 parameters, 7124812 gradients, 16.3 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00039\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 33.4\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.26 anchors/target, 0.709 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 18 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8490: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.18: 1.0000 best possible recall, 15.08 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=18, img_size=640, metric_all=0.428/0.849-mean/best, past_thr=0.490-mean: 13,12, 25,20, 22,33, 39,23, 32,29, 32,42, 43,37, 55,31, 38,56, 54,47, 60,64, 81,47, 68,85, 113,74, 118,108, 199,98, 226,238, 536,259\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.514G   0.07979   0.03774   0.07115         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.514G   0.05531   0.03627    0.0649         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.514G   0.04964   0.03228    0.0617         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.514G   0.04509   0.03416   0.05887         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.514G   0.03969   0.03168   0.05535        13       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.514G   0.03599   0.03183   0.05335        10       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.514G   0.03549   0.03103   0.05139         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.514G   0.03349   0.03054    0.0491         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.514G   0.03324   0.02977   0.04819         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.514G   0.03379    0.0299   0.04599         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.514G   0.03265   0.02957   0.04422         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.514G   0.03198   0.02881   0.04225         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.514G   0.03193    0.0286   0.03931         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.514G   0.03165   0.02813   0.03595        11       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.514G   0.03121   0.02922   0.03448         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.514G   0.03139   0.02791   0.03244         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.514G   0.03064   0.02715   0.03143         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.514G   0.03023   0.02785   0.02819         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.514G   0.03026   0.02788   0.02678         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.514G   0.02935   0.02844   0.02539         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.514G   0.02851   0.02718   0.02396         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.514G   0.02873   0.02705   0.02174         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.514G   0.02837   0.02636   0.02128         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.514G   0.02814   0.02504   0.02057         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.514G   0.02698   0.02641   0.01924         3       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.625      0.611      0.633      0.346\n",
      "\n",
      "25 epochs completed in 0.411 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▇▅▆▅▅▄▄▄▄▃▃▃▃▃▃▂▃▃▃▂▂▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▅████▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▅████▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.63291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.34647\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.6246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.61131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.63291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.34647\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.6246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.61131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.02698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02659\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01844\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mwoven-planet-498\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/23j84b2r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_212918-23j84b2r/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m11 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m              0.6246,              0.61131,              0.63291,              0.34647,             0.026589,             0.024544,             0.018435,              0.01051,              0.01271,                 0.98,              0.00039,               3.2871,              0.82682,              0.07301,              0.03529,              0.47461,              0.98422,              0.87173,                1.152,                  0.2,                5.646,                    0,              0.01641,              0.67406,              0.35862,                    0,              0.10723,              0.50993,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               5.6137\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01291, lrf=0.01264, momentum=0.98, weight_decay=0.00045, warmup_epochs=2.9281, warmup_momentum=0.68598, warmup_bias_lr=0.05579, box=0.05519, cls=0.42593, cls_pw=1.12647, obj=0.6963, obj_pw=1.34221, iou_t=0.2, anchor_t=4.6247, fl_gamma=0.0, hsv_h=0.01808, hsv_s=0.72268, hsv_v=0.34716, degrees=0.0, translate=0.08637, scale=0.44075, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.93883, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_215445-6luwzq89\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mskilled-sun-499\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/6luwzq89\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00045\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:32<00:00, 33.5\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.04 anchors/target, 0.014 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7742: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.22: 1.0000 best possible recall, 5.39 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.492/0.774-mean/best, past_thr=0.529-mean: 24,20, 40,27, 31,42, 54,43, 69,66, 129,108\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.499G    0.1144   0.03476   0.06974         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.499G   0.08759   0.03088   0.06228         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.499G   0.08396   0.03256   0.05947         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.499G   0.07482    0.0336   0.05713         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.499G   0.06437   0.03074   0.05332         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.501G   0.05999   0.03009   0.05074         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.501G   0.05914   0.03031   0.05021         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.501G   0.05606   0.02946    0.0478         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.501G   0.05553   0.03044   0.04503         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.501G   0.05315   0.02878   0.04388         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.501G   0.05327   0.02975   0.04157         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.501G   0.05076   0.02975   0.03977         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.501G   0.05024   0.02982   0.03881         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.501G   0.04978   0.02741   0.03641         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.501G   0.04985   0.02995   0.03518         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.501G   0.04854   0.02674   0.03332         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.501G   0.04727   0.02758   0.03296         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.501G   0.04895    0.0283    0.0302         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.501G   0.04569   0.02758   0.02898         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.501G    0.0449   0.02528   0.02877         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.501G   0.04526   0.02633   0.02631         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.501G    0.0439   0.02602     0.026         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.501G   0.04337    0.0256   0.02447         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.501G   0.04272   0.02473   0.02437         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.501G   0.04228   0.02551   0.02294         1       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.613      0.537       0.58      0.333\n",
      "\n",
      "25 epochs completed in 0.416 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▅▄▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▅▆▇▅▅▅▄▅▄▅▅▅▃▅▂▃▃▃▁▂▂▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.58029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.33327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.61327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.53731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.58029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.33327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.61327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.53731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04228\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02551\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02283\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02427\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00118\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00118\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00118\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mskilled-sun-499\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/6luwzq89\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_215445-6luwzq89/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m12 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.61327,              0.53731,              0.58029,              0.33327,             0.039965,             0.024267,             0.022829,              0.01291,              0.01264,                 0.98,              0.00045,               2.9281,              0.68598,              0.05579,              0.05519,              0.42593,               1.1265,               0.6963,               1.3422,                  0.2,               4.6247,                    0,              0.01808,              0.72268,              0.34716,                    0,              0.08637,              0.44075,                    0,                    0,                    0,                  0.5,              0.93883,                    0,                    0,                    2\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00818, lrf=0.01154, momentum=0.98, weight_decay=0.00057, warmup_epochs=3.13916, warmup_momentum=0.73893, warmup_bias_lr=0.06153, box=0.05294, cls=0.50886, cls_pw=1.0658, obj=0.6963, obj_pw=1.09641, iou_t=0.2, anchor_t=5.73193, fl_gamma=0.0, hsv_h=0.01856, hsv_s=0.72535, hsv_v=0.38324, degrees=0.0, translate=0.10723, scale=0.40888, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=7.64228\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_222031-37xp6xia\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mglamorous-surf-500\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/37xp6xia\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=7.64228\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1    158224  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7164368 parameters, 7164368 gradients, 16.4 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00057\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:33<00:00, 33.4\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m10.40 anchors/target, 0.868 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 24 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8682: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.17: 1.0000 best possible recall, 20.50 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=24, img_size=640, metric_all=0.426/0.868-mean/best, past_thr=0.479-mean: 11,10, 18,15, 21,24, 28,20, 23,36, 39,23, 32,29, 36,39, 54,28, 34,50, 48,37, 53,47, 44,64, 74,42, 68,59, 55,81, 100,57, 81,76, 123,81, 80,135, 132,122, 194,112, 229,226, 475,280\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.518G    0.1228   0.03059   0.08277         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.518G   0.08408   0.03821   0.07668         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.518G   0.07495    0.0293   0.07292         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.518G    0.0668   0.02754   0.07003         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.518G   0.05895   0.02631   0.06889         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.518G   0.05364   0.02687   0.06644         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.518G   0.05163   0.02635   0.06495         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.518G   0.05083   0.02587   0.06342         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.518G    0.0489   0.02511   0.06121         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.518G    0.0493   0.02467   0.06007         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.518G   0.04718   0.02508   0.05797         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.518G   0.04775   0.02426   0.05723         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.518G   0.04524   0.02291   0.05477         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.518G   0.04457   0.02322   0.05473         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.518G   0.04539   0.02197   0.05307        10       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.518G    0.0441   0.02388   0.05128         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.518G   0.04329    0.0226    0.0495         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.518G   0.04223   0.02295   0.04867         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.518G   0.04207    0.0222   0.04596         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.518G   0.04295    0.0229    0.0446         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.518G   0.04114   0.02223   0.04235         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.518G   0.04147   0.02122   0.04132         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.518G    0.0405   0.02085   0.03919         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.518G   0.04001   0.02118   0.03813         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.518G   0.03977   0.02108   0.03737         2       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.449      0.504      0.458      0.256\n",
      "\n",
      "25 epochs completed in 0.407 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅█▄▄▃▃▃▃▃▃▃▂▂▂▁▂▂▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.45795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.25606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.44909\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.50408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.45795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.25606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.44909\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.50408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.03737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02108\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03675\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01974\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mglamorous-surf-500\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/37xp6xia\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_222031-37xp6xia/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m13 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.44909,              0.50408,              0.45795,              0.25606,             0.038202,             0.019736,             0.036753,              0.00818,              0.01154,                 0.98,              0.00057,               3.1392,              0.73893,              0.06153,              0.05294,              0.50886,               1.0658,               0.6963,               1.0964,                  0.2,               5.7319,                    0,              0.01856,              0.72535,              0.38324,                    0,              0.10723,              0.40888,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               7.6423\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00964, lrf=0.01, momentum=0.98, weight_decay=0.00047, warmup_epochs=3.81924, warmup_momentum=0.5126, warmup_bias_lr=0.0787, box=0.0537, cls=0.50082, cls_pw=1.0658, obj=0.72584, obj_pw=1.2274, iou_t=0.2, anchor_t=4.6247, fl_gamma=0.0, hsv_h=0.01938, hsv_s=0.76386, hsv_v=0.34986, degrees=0.0, translate=0.08989, scale=0.37589, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3.00919\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_224544-glgxevbq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbalmy-blaze-501\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/glgxevbq\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=3.00919\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00047\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:33<00:00, 33.2\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.23 anchors/target, 0.062 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.22: 1.0000 best possible recall, 7.33 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.514-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.501G    0.1228   0.03111   0.08145         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.503G   0.08942   0.03327   0.07378         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.503G   0.08006   0.02924   0.06906         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.503G   0.07322   0.02762   0.06645        16       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.503G   0.06555   0.02728    0.0627         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.503G   0.05768   0.02808   0.05741         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.503G   0.05493   0.02735   0.05344         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.503G   0.05269    0.0269   0.05142         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.503G   0.05317   0.02764   0.04769         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.503G   0.05115   0.02723   0.04485         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.503G   0.04939    0.0264   0.04156         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.503G   0.05025   0.02626   0.03953         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.503G    0.0467   0.02491   0.03726         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.503G   0.04675   0.02551   0.03391         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.503G   0.04689   0.02438   0.03249         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.503G   0.04628   0.02433   0.03062         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.503G   0.04582   0.02563   0.02817         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.503G    0.0447   0.02347   0.02612         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.503G   0.04341   0.02323    0.0254         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.503G   0.04328   0.02277   0.02345         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.503G   0.04309   0.02347    0.0226         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.503G    0.0419   0.02254    0.0209         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.503G   0.04045   0.02268   0.02067         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.503G   0.03987   0.02249   0.01966         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.503G   0.03984   0.02203    0.0183        26       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.679      0.625      0.669      0.382\n",
      "\n",
      "25 epochs completed in 0.421 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▇█▅▄▄▅▄▄▄▄▄▄▃▃▂▂▃▂▂▁▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▆▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▅▇███▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▅▇███▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.66949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.38246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.67948\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.62454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.66949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.38246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.67948\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.62454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0183\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03919\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01686\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mbalmy-blaze-501\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/glgxevbq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_224544-glgxevbq/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m14 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.67948,              0.62454,              0.66949,              0.38246,             0.039189,              0.02127,             0.016858,              0.00964,                 0.01,                 0.98,              0.00047,               3.8192,               0.5126,               0.0787,               0.0537,              0.50082,               1.0658,              0.72584,               1.2274,                  0.2,               4.6247,                    0,              0.01938,              0.76386,              0.34986,                    0,              0.08989,              0.37589,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               3.0092\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00999, lrf=0.01027, momentum=0.98, weight_decay=0.00058, warmup_epochs=3.18974, warmup_momentum=0.75082, warmup_bias_lr=0.06005, box=0.04374, cls=0.49223, cls_pw=1.0435, obj=0.65719, obj_pw=1.11318, iou_t=0.2, anchor_t=4.4033, fl_gamma=0.0, hsv_h=0.0183, hsv_s=0.66319, hsv_v=0.38095, degrees=0.0, translate=0.10728, scale=0.46039, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.98067, mixup=0.0, copy_paste=0.0, anchors=3.34308\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_231147-608qpq4e\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfrosty-tree-502\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/608qpq4e\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=3.34308\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00058\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:33<00:00, 33.0\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.20 anchors/target, 0.054 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 7.20 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.519-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.501G   0.09442    0.0269   0.07671         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.501G   0.06549   0.02608   0.06833         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.501G   0.06132   0.02375   0.06447         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.501G   0.05392   0.02286   0.06008         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.501G   0.04897   0.02261   0.05496         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.501G   0.04561   0.02367    0.0517         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.503G   0.04399   0.02183   0.04681         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.503G   0.04307   0.02163   0.04336         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.503G   0.04152   0.02265   0.04057         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.503G   0.04182   0.02231   0.03747         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.503G   0.04125   0.02202   0.03552         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.503G   0.04082   0.02164   0.03308         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.503G    0.0397   0.02102   0.03082         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.503G   0.03914   0.02049   0.02897         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.503G   0.03828   0.02077   0.02792         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.503G   0.03807   0.02053   0.02613         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.503G   0.03786   0.02128    0.0236         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.503G   0.03756   0.01977   0.02123         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.503G   0.03705   0.02037   0.02153         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.503G   0.03668   0.01947   0.01909         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.503G   0.03531   0.02005   0.01826         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.503G   0.03543   0.01901   0.01672         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.503G   0.03497   0.01953   0.01698         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.503G   0.03345   0.01928   0.01529         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.503G   0.03236   0.01885   0.01425         2       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616       0.75      0.647      0.694       0.39\n",
      "\n",
      "25 epochs completed in 0.424 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▇▅▄▄▅▄▃▄▄▄▃▃▂▃▂▃▂▂▂▂▁▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.69405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.38972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.75045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.64698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.69405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.38972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.75045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.64698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01885\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01338\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01748\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfrosty-tree-502\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/608qpq4e\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_231147-608qpq4e/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m15 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.75045,              0.64698,              0.69405,              0.38972,             0.031921,             0.017484,             0.013381,              0.00999,              0.01027,                 0.98,              0.00058,               3.1897,              0.75082,              0.06005,              0.04374,              0.49223,               1.0435,              0.65719,               1.1132,                  0.2,               4.4033,                    0,               0.0183,              0.66319,              0.38095,                    0,              0.10728,              0.46039,                    0,                    0,                    0,                  0.5,              0.98067,                    0,                    0,               3.3431\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00829, lrf=0.01091, momentum=0.98, weight_decay=0.00057, warmup_epochs=4.19694, warmup_momentum=0.77217, warmup_bias_lr=0.05999, box=0.05464, cls=0.48765, cls_pw=1.56838, obj=0.92102, obj_pw=1.1435, iou_t=0.2, anchor_t=4.4033, fl_gamma=0.0, hsv_h=0.02068, hsv_s=0.7805, hsv_v=0.26199, degrees=0.0, translate=0.1039, scale=0.33877, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=5.91461\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220727_233801-lkbr4knw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgenial-firebrand-503\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/lkbr4knw\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=5.91461\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1    118668  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7124812 parameters, 7124812 gradients, 16.3 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00057\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:33<00:00, 32.9\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.46 anchors/target, 0.536 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 18 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8490: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 13.89 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=18, img_size=640, metric_all=0.428/0.849-mean/best, past_thr=0.515-mean: 13,12, 25,20, 22,33, 39,23, 32,29, 32,42, 43,37, 55,31, 38,56, 54,47, 60,64, 81,47, 68,85, 113,74, 118,108, 199,98, 226,238, 536,259\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.514G    0.1225   0.03957    0.1076         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.514G   0.08277   0.04171   0.09547         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.514G   0.07519   0.03445   0.08978         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.514G   0.07283   0.03358   0.08464         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.514G   0.06551   0.03036   0.07848        13       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.514G   0.05577   0.03024   0.07333         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.514G    0.0536   0.03028   0.06977         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.514G    0.0504   0.02981   0.06528         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.514G   0.05029   0.02845   0.06171         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.514G   0.05016   0.02932    0.0578         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.514G   0.04961   0.02894   0.05324         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.514G   0.04824   0.02806    0.0491         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.514G    0.0478   0.02786   0.04429         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.514G   0.04715   0.02719   0.04049        10       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.514G   0.04704    0.0287   0.03923         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.514G   0.04603   0.02691   0.03516         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.514G   0.04535   0.02662   0.03398         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.514G   0.04409   0.02711   0.03006         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.514G   0.04384   0.02702   0.02781         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.514G   0.04256   0.02723   0.02641         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.514G   0.04216   0.02607    0.0252         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.514G   0.04219   0.02622   0.02344         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.514G   0.04049   0.02521   0.02223         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.514G   0.04062   0.02406   0.02019         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.514G   0.03886   0.02516   0.01899         3       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.739      0.617      0.686      0.381\n",
      "\n",
      "25 epochs completed in 0.423 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▇█▅▅▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▆▄▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▄▆████▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▂▄▆████▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.68599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.38092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.73851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.61701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.68599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.38092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.73851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.61701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03886\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01899\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03892\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02385\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgenial-firebrand-503\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/lkbr4knw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_233801-lkbr4knw/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m16 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.73851,              0.61701,              0.68599,              0.38092,             0.038918,             0.023852,             0.019906,              0.00829,              0.01091,                 0.98,              0.00057,               4.1969,              0.77217,              0.05999,              0.05464,              0.48765,               1.5684,              0.92102,               1.1435,                  0.2,               4.4033,                    0,              0.02068,               0.7805,              0.26199,                    0,               0.1039,              0.33877,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               5.9146\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0097, lrf=0.01, momentum=0.98, weight_decay=0.00057, warmup_epochs=3.08505, warmup_momentum=0.82329, warmup_bias_lr=0.05991, box=0.03361, cls=0.36899, cls_pw=1.28292, obj=0.66803, obj_pw=1.16727, iou_t=0.2, anchor_t=5.12358, fl_gamma=0.0, hsv_h=0.02245, hsv_s=0.67856, hsv_v=0.38262, degrees=0.0, translate=0.08442, scale=0.4295, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.80593, mixup=0.0, copy_paste=0.0, anchors=4.50208\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220728_000411-jk2r543f\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33munique-music-504\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/jk2r543f\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=4.50208\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     98890  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7105034 parameters, 7105034 gradients, 16.2 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00057\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:34<00:00, 32.3\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.56 anchors/target, 0.481 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 15 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8370: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.20: 1.0000 best possible recall, 11.81 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=15, img_size=640, metric_all=0.414/0.837-mean/best, past_thr=0.494-mean: 14,13, 24,20, 23,34, 32,24, 35,37, 50,29, 37,55, 55,44, 73,56, 61,74, 106,79, 113,120, 203,109, 206,257, 475,277\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.501G   0.07359   0.02661   0.06883         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.501G   0.04962   0.02714   0.06165         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.501G   0.04652   0.02237   0.05791        24       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.501G   0.04309   0.02197    0.0559         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.501G   0.03559   0.02152   0.05253         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.501G   0.03343   0.02225   0.04927         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.501G   0.03209   0.02249   0.04772        28       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.501G   0.03087   0.02085   0.04562         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.501G   0.03047   0.02018   0.04456         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.501G   0.03093   0.02078   0.04295         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.501G   0.03011   0.01962   0.04012         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.501G   0.02957   0.01993    0.0379         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.501G   0.02947   0.02042   0.03526         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.501G   0.02949   0.02002   0.03308         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.501G   0.02921   0.02007   0.03064         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.501G   0.02899   0.01941   0.02895         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.501G   0.02842    0.0191   0.02606         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.501G   0.02759   0.01878   0.02566         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.501G   0.02727   0.01833   0.02342         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.501G   0.02672   0.01877   0.02192        28       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.501G   0.02682   0.01835   0.02022         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.501G   0.02595   0.01821   0.01911         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.501G   0.02591   0.01799   0.01769         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.501G   0.02543   0.01846    0.0175         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.501G   0.02453   0.01754   0.01636         2       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.657       0.59      0.637      0.351\n",
      "\n",
      "25 epochs completed in 0.441 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▅▅▅▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ██▅▄▄▄▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆████▇▇▇▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆████▇▇▇▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.63678\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.35099\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.65709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.58992\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.63678\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.35099\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.65709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.58992\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.02453\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33munique-music-504\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/jk2r543f\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220728_000411-jk2r543f/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m17 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.65709,              0.58992,              0.63678,              0.35099,             0.024708,             0.018152,              0.01595,               0.0097,                 0.01,                 0.98,              0.00057,                3.085,              0.82329,              0.05991,              0.03361,              0.36899,               1.2829,              0.66803,               1.1673,                  0.2,               5.1236,                    0,              0.02245,              0.67856,              0.38262,                    0,              0.08442,               0.4295,                    0,                    0,                    0,                  0.5,              0.80593,                    0,                    0,               4.5021\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00934, lrf=0.01056, momentum=0.98, weight_decay=0.00059, warmup_epochs=3.2469, warmup_momentum=0.78857, warmup_bias_lr=0.05999, box=0.04034, cls=0.52143, cls_pw=1.01764, obj=0.70346, obj_pw=1.16128, iou_t=0.2, anchor_t=4.16984, fl_gamma=0.0, hsv_h=0.01884, hsv_s=0.65997, hsv_v=0.42198, degrees=0.0, translate=0.10102, scale=0.45084, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.96128, mixup=0.0, copy_paste=0.0, anchors=3.3585\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220728_003129-julgvhh8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfluent-monkey-505\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/julgvhh8\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=3.3585\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00059\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:33<00:00, 32.5\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.18 anchors/target, 0.048 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 7.07 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.525-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.501G   0.08631   0.02934   0.07904         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.501G   0.05981   0.02839   0.07046         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.503G   0.05495   0.02465   0.06664         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.503G   0.05091   0.02514   0.06102        20       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.503G    0.0437   0.02438   0.05602         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.503G   0.04113    0.0242   0.05148         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.503G   0.04094   0.02354   0.04796         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.503G   0.03844   0.02326   0.04476         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.503G   0.03952   0.02317   0.04059         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.503G   0.03823   0.02417   0.03809         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.503G   0.03762   0.02241   0.03434         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.503G   0.03729   0.02273   0.03215         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.503G   0.03608   0.02165   0.02935        11       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.503G   0.03542    0.0208   0.02613         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.503G   0.03547   0.02259   0.02456         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.503G   0.03459   0.02146    0.0232         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.503G   0.03449   0.02129   0.02192         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.503G   0.03444   0.02151   0.01955         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.503G   0.03307   0.02083   0.01859         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.503G   0.03349   0.02122   0.01777         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.503G   0.03218   0.02087   0.01672         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.503G   0.03095   0.02009   0.01435         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.503G   0.03162   0.02049   0.01596         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.503G   0.03061   0.02026   0.01415         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.503G    0.0296   0.01932   0.01323         3       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.736      0.649      0.697      0.394\n",
      "\n",
      "25 epochs completed in 0.422 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▅▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▇▅▅▅▄▄▄▄▄▃▃▃▂▃▂▂▃▂▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▅████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▅████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.69711\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.39369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.73577\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.64887\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.69711\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.39369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.73577\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.64887\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0296\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01885\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfluent-monkey-505\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/julgvhh8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220728_003129-julgvhh8/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m18 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.73577,              0.64887,              0.69711,              0.39369,             0.028749,             0.018854,             0.013814,              0.00934,              0.01056,                 0.98,              0.00059,               3.2469,              0.78857,              0.05999,              0.04034,              0.52143,               1.0176,              0.70346,               1.1613,                  0.2,               4.1698,                    0,              0.01884,              0.65997,              0.42198,                    0,              0.10102,              0.45084,                    0,                    0,                    0,                  0.5,              0.96128,                    0,                    0,               3.3585\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00869, lrf=0.01174, momentum=0.90989, weight_decay=0.00055, warmup_epochs=2.67943, warmup_momentum=0.67863, warmup_bias_lr=0.05999, box=0.03739, cls=0.51794, cls_pw=1.25569, obj=0.75834, obj_pw=1.1435, iou_t=0.2, anchor_t=4.12627, fl_gamma=0.0, hsv_h=0.01842, hsv_s=0.68903, hsv_v=0.41058, degrees=0.0, translate=0.10043, scale=0.43999, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.88902, mixup=0.0, copy_paste=0.0, anchors=5.19174\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220728_005737-vo8z7orm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mamber-rain-506\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/vo8z7orm\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=5.19174\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     98890  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7105034 parameters, 7105034 gradients, 16.2 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00055\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:33<00:00, 32.6\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.56 anchors/target, 0.315 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 15 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8370: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 10.82 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=15, img_size=640, metric_all=0.414/0.837-mean/best, past_thr=0.519-mean: 14,13, 24,20, 23,34, 32,24, 35,37, 50,29, 37,55, 55,44, 73,56, 61,74, 106,79, 113,120, 203,109, 206,257, 475,277\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.501G   0.08332   0.03016   0.09515         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.501G   0.05987   0.03048   0.08458         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.501G   0.05652   0.02487   0.07891         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.501G    0.0483   0.02322   0.07234         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.501G   0.04207   0.02314   0.06754         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.501G   0.04099   0.02233   0.06332         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.501G    0.0372   0.02282   0.05975         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.501G   0.03587   0.02141   0.05458         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.501G    0.0372   0.02211   0.05105        12       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.501G   0.03604   0.02078    0.0464         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.501G   0.03543   0.02104   0.04246         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.501G   0.03593   0.02082   0.03867         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.501G   0.03456    0.0203   0.03384         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.501G   0.03431   0.01969   0.03128         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.501G    0.0348   0.01988   0.02834         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.501G   0.03255   0.01864   0.02679         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.501G   0.03237   0.01848   0.02467         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.501G   0.03235   0.01947   0.02336         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.501G   0.03109   0.01996   0.02164         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.501G    0.0302   0.01933   0.02032         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.501G   0.02976    0.0183   0.01816         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.501G   0.02854   0.01839   0.01796         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.501G   0.02763   0.01911   0.01689         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.501G   0.02674   0.01754   0.01542         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.501G   0.02638   0.01814   0.01528         5       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.697      0.695      0.704       0.39\n",
      "\n",
      "25 epochs completed in 0.411 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▅▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ██▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.70376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.38977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.6971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.69524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.70376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.38977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.6971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.69524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.02638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01528\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00079\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00079\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00079\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mamber-rain-506\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/vo8z7orm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220728_005737-vo8z7orm/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m19 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m              0.6971,              0.69524,              0.70376,              0.38977,             0.026709,             0.017915,              0.01743,              0.00869,              0.01174,              0.90989,              0.00055,               2.6794,              0.67863,              0.05999,              0.03739,              0.51794,               1.2557,              0.75834,               1.1435,                  0.2,               4.1263,                    0,              0.01842,              0.68903,              0.41058,                    0,              0.10043,              0.43999,                    0,                    0,                    0,                  0.5,              0.88902,                    0,                    0,               5.1917\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0097, lrf=0.01078, momentum=0.98, weight_decay=0.00051, warmup_epochs=3.05694, warmup_momentum=0.76571, warmup_bias_lr=0.05513, box=0.04597, cls=0.51652, cls_pw=1.22777, obj=0.66886, obj_pw=1.1435, iou_t=0.2, anchor_t=4.4033, fl_gamma=0.0, hsv_h=0.01702, hsv_s=0.65997, hsv_v=0.38656, degrees=0.0, translate=0.0941, scale=0.49921, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.89477, mixup=0.0, copy_paste=0.0, anchors=2.45665\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220728_012309-2ytvnkue\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcolorful-frost-507\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2ytvnkue\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=2.45665\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     39556  models.yolo.Detect                      [17, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7045700 parameters, 7045700 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00051\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:33<00:00, 33.2\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.04 anchors/target, 0.013 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7761: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 5.36 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=640, metric_all=0.495/0.776-mean/best, past_thr=0.534-mean: 22,19, 37,25, 29,38, 50,41, 66,64, 121,101\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.499G   0.09671   0.02911   0.08897         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.499G   0.07081   0.02698   0.07847         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.499G   0.06664   0.02735   0.07024         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.499G   0.05923    0.0252   0.06114         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.499G   0.05328   0.02574   0.05481         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.499G   0.05208   0.02596   0.04848         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.499G   0.04934   0.02508   0.04376         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.499G   0.04733   0.02504   0.04357         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.501G   0.04677   0.02599   0.03968         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.501G   0.04553   0.02356   0.03618         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.501G   0.04559   0.02448   0.03497         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.501G   0.04407   0.02461   0.03327         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.501G   0.04428   0.02491   0.03234         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.501G   0.04338   0.02324   0.02968         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.501G   0.04344   0.02384    0.0284         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.501G   0.04215   0.02324   0.02613         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.501G   0.04202   0.02244     0.025         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.501G   0.04014    0.0228   0.02239         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.501G   0.04012   0.02442   0.02102         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.501G   0.03846    0.0221   0.01889         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.501G   0.03811   0.02226   0.01909         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.501G   0.03804   0.02287   0.01866         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.501G   0.03725   0.02148   0.01857         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.501G    0.0372   0.02162   0.01647         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.501G   0.03623   0.02118   0.01756         0       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.688      0.631      0.663      0.368\n",
      "\n",
      "25 epochs completed in 0.417 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▆▆▅▅▅▄▄▅▃▄▄▄▃▃▃▂▂▄▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.66288\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.36838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.68754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.63128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.66288\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.36838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.68754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.63128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03623\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01756\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02118\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0342\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01573\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mcolorful-frost-507\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/2ytvnkue\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220728_012309-2ytvnkue/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m20 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.68754,              0.63128,              0.66288,              0.36838,             0.034201,             0.021912,             0.015727,               0.0097,              0.01078,                 0.98,              0.00051,               3.0569,              0.76571,              0.05513,              0.04597,              0.51652,               1.2278,              0.66886,               1.1435,                  0.2,               4.4033,                    0,              0.01702,              0.65997,              0.38656,                    0,               0.0941,              0.49921,                    0,                    0,                    0,                  0.5,              0.89477,                    0,                    0,               2.4566\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0097, lrf=0.01, momentum=0.98, weight_decay=0.00056, warmup_epochs=3.54116, warmup_momentum=0.73595, warmup_bias_lr=0.05999, box=0.0407, cls=0.58122, cls_pw=0.97218, obj=0.66803, obj_pw=1.1435, iou_t=0.2, anchor_t=4.49442, fl_gamma=0.0, hsv_h=0.02123, hsv_s=0.65997, hsv_v=0.37613, degrees=0.0, translate=0.09774, scale=0.45472, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.94532, mixup=0.0, copy_paste=0.0, anchors=3.34129\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220728_014856-1r98jabx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mworthy-morning-508\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1r98jabx\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=3.34129\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00056\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:33<00:00, 32.9\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.21 anchors/target, 0.058 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.22: 1.0000 best possible recall, 7.25 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.517-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.516G   0.08981   0.02748   0.08591         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.516G   0.06231    0.0276   0.07633         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.518G    0.0579   0.02475    0.0716         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.518G   0.05375   0.02445   0.06561        16       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.518G   0.04795   0.02314   0.05884         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.518G   0.04324   0.02286   0.05423         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.518G   0.04095   0.02332   0.04965         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.518G   0.04114   0.02257   0.04506         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.518G    0.0396   0.02272   0.04103         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.518G   0.03971   0.02308   0.03723         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.518G   0.04025   0.02249   0.03583         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.518G   0.03862   0.02207   0.03242         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.518G   0.03797   0.02192   0.03067         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.518G   0.03727   0.02196    0.0284         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.518G   0.03767   0.02244   0.02692         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.518G   0.03654   0.02112   0.02605        21       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.518G    0.0354   0.02165   0.02365         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.518G   0.03566   0.02041   0.02207         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.518G   0.03427   0.02034   0.02066         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.518G   0.03429   0.02093   0.01906        22       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.518G    0.0331   0.02046   0.01968         8       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.518G   0.03292   0.02019   0.01687         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.518G   0.03303   0.01984   0.01785         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.518G   0.03197   0.01951   0.01575         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.518G   0.03137   0.01934   0.01539         9       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.683      0.704       0.71      0.408\n",
      "\n",
      "25 epochs completed in 0.418 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ██▆▅▄▄▄▄▄▄▄▃▃▃▄▃▃▂▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▆▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▅▇███▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▅▇███▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.71027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.40783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.68319\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.70437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.71027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.40783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.68319\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.70437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03137\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01934\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mworthy-morning-508\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/1r98jabx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220728_014856-1r98jabx/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m21 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.68319,              0.70437,              0.71027,              0.40783,               0.0294,             0.018273,             0.015945,               0.0097,                 0.01,                 0.98,              0.00056,               3.5412,              0.73595,              0.05999,               0.0407,              0.58122,              0.97218,              0.66803,               1.1435,                  0.2,               4.4944,                    0,              0.02123,              0.65997,              0.37613,                    0,              0.09774,              0.45472,                    0,                    0,                    0,                  0.5,              0.94532,                    0,                    0,               3.3413\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01056, lrf=0.01, momentum=0.97788, weight_decay=0.00065, warmup_epochs=3.11556, warmup_momentum=0.64369, warmup_bias_lr=0.06403, box=0.04781, cls=0.51611, cls_pw=1.04042, obj=0.69508, obj_pw=1.1435, iou_t=0.2, anchor_t=4.13306, fl_gamma=0.0, hsv_h=0.01901, hsv_s=0.65997, hsv_v=0.40897, degrees=0.0, translate=0.10337, scale=0.42522, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.97341\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220728_021448-h29p1hk4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflowing-wood-509\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/h29p1hk4\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=2.97341\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00065\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:33<00:00, 33.0\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.18 anchors/target, 0.047 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 7.04 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.526-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.501G    0.1048   0.02869    0.0809         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.503G   0.07418   0.02844   0.07241         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.503G   0.06812   0.02545   0.06773         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.503G      0.06   0.02416   0.06308        17       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.503G   0.05312   0.02367   0.05894         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.503G   0.04911   0.02425   0.05442         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.503G   0.04682   0.02351   0.05053         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.503G   0.04613   0.02321   0.04787         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.503G   0.04622   0.02427   0.04399         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.503G   0.04435   0.02366   0.04004         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.503G   0.04381   0.02251   0.03691         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.503G   0.04443    0.0227   0.03513         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.503G   0.04143   0.02147   0.03289         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.503G   0.04154    0.0225   0.02965         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.503G   0.04139   0.02135   0.02818         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.503G    0.0413   0.02161   0.02663         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.503G   0.04049   0.02244   0.02453         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.503G     0.039   0.02032   0.02174         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.503G   0.03858   0.02031   0.02117         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.503G   0.03876    0.0199   0.01989         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.503G   0.03857   0.02049   0.01942         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.503G   0.03674    0.0197   0.01758         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.503G   0.03576   0.01956   0.01707         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.503G   0.03509   0.01975   0.01635         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.503G   0.03535   0.01928   0.01476        30       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.708      0.675      0.701      0.398\n",
      "\n",
      "25 epochs completed in 0.420 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ██▆▅▄▅▄▄▅▄▃▄▃▃▃▃▃▂▂▁▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.70068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.39842\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.70774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.67509\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.70068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.39842\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.70774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.67509\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01476\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03442\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mflowing-wood-509\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/h29p1hk4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220728_021448-h29p1hk4/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m22 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.70774,              0.67509,              0.70068,              0.39842,             0.034418,             0.018191,              0.01353,              0.01056,                 0.01,              0.97788,              0.00065,               3.1156,              0.64369,              0.06403,              0.04781,              0.51611,               1.0404,              0.69508,               1.1435,                  0.2,               4.1331,                    0,              0.01901,              0.65997,              0.40897,                    0,              0.10337,              0.42522,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.9734\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0097, lrf=0.01, momentum=0.94134, weight_decay=0.00069, warmup_epochs=3.34249, warmup_momentum=0.76165, warmup_bias_lr=0.06317, box=0.04383, cls=0.51652, cls_pw=1.0435, obj=0.64252, obj_pw=1.16156, iou_t=0.2, anchor_t=4.41919, fl_gamma=0.0, hsv_h=0.01795, hsv_s=0.74049, hsv_v=0.39668, degrees=0.0, translate=0.11043, scale=0.45472, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.92902, mixup=0.0, copy_paste=0.0, anchors=2.98458\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220728_024047-604k9yrr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwise-moon-510\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/604k9yrr\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=2.98458\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00069\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:33<00:00, 32.8\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.21 anchors/target, 0.055 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 7.22 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.519-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.501G   0.09522   0.02644   0.08028         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.501G   0.06634   0.02801   0.07162         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.501G   0.06189   0.02461   0.06791         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.501G    0.0568   0.02316   0.06336         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.501G   0.05193   0.02292   0.05781         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.501G   0.04674    0.0215   0.05342         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.503G   0.04426   0.02153     0.049         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.503G   0.04369   0.02141   0.04478         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.503G   0.04261   0.02081   0.04041         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.503G   0.04306   0.02041   0.03566         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.503G   0.04246    0.0202   0.03321         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.503G   0.04142   0.01955   0.03068         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.503G   0.04016   0.01996   0.02763         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.503G   0.03879   0.01917   0.02469         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.503G   0.03924   0.02001   0.02319         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.503G   0.03706   0.01995   0.02262         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.503G    0.0381   0.01936   0.01976         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.503G   0.03618   0.01837   0.01736         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.503G   0.03599   0.01793   0.01763         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.503G   0.03503   0.01867   0.01653         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.503G   0.03332   0.01747   0.01507         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.503G   0.03291   0.01805   0.01303         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.503G   0.03286   0.01785   0.01375         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.503G   0.03145   0.01758   0.01285         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.503G   0.03074   0.01715   0.01199         6       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.754      0.697      0.734      0.436\n",
      "\n",
      "25 epochs completed in 0.424 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▇█▆▅▅▄▄▄▃▃▃▃▃▂▃▃▂▂▂▂▁▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▆▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▅████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▅████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.73432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.4363\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.75435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.6972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.73432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.4363\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.75435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.6972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01715\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03037\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01643\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mwise-moon-510\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/604k9yrr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220728_024047-604k9yrr/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m23 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.75435,               0.6972,              0.73432,               0.4363,             0.030374,             0.016426,             0.012927,               0.0097,                 0.01,              0.94134,              0.00069,               3.3425,              0.76165,              0.06317,              0.04383,              0.51652,               1.0435,              0.64252,               1.1616,                  0.2,               4.4192,                    0,              0.01795,              0.74049,              0.39668,                    0,              0.11043,              0.45472,                    0,                    0,                    0,                  0.5,              0.92902,                    0,                    0,               2.9846\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00609, lrf=0.01, momentum=0.92501, weight_decay=0.00046, warmup_epochs=3.04401, warmup_momentum=0.8586, warmup_bias_lr=0.09795, box=0.05176, cls=0.5398, cls_pw=0.97224, obj=1.31515, obj_pw=0.90869, iou_t=0.2, anchor_t=3.19908, fl_gamma=0.0, hsv_h=0.01402, hsv_s=0.48381, hsv_v=0.30328, degrees=0.0, translate=0.10739, scale=0.42237, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.80816, mixup=0.0, copy_paste=0.0, anchors=3.0\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220728_030703-3j6v9y7i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfeasible-eon-511\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3j6v9y7i\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=3.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00046\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:33<00:00, 32.9\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.09 anchors/target, 0.027 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8027: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.31: 1.0000 best possible recall, 6.17 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.446/0.803-mean/best, past_thr=0.564-mean: 17,16, 26,25, 41,27, 32,41, 52,41, 50,69, 79,63, 120,109, 271,270\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.501G    0.1044   0.03886    0.0782         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.501G    0.0725   0.03668    0.0711         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.501G   0.06624    0.0319   0.06842         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.501G   0.06049    0.0318   0.06526        27       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.503G   0.05423   0.03145   0.06325         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.503G   0.05006   0.02941   0.05996         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.503G   0.04715   0.03051   0.05617         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.503G    0.0472   0.02868   0.05381         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.503G   0.04639   0.02735   0.05063         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.503G   0.04428   0.02876   0.04689         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.503G   0.04471   0.02682    0.0447         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.503G   0.04224   0.02648   0.04085         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.503G   0.04359   0.02606   0.03831         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.503G    0.0408    0.0253   0.03542         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.503G   0.04081   0.02571   0.03225         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.503G   0.04178   0.02705   0.03063         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.503G   0.04061   0.02471   0.02853         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.503G   0.03878   0.02464   0.02623         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.503G   0.03876   0.02534   0.02486         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.503G   0.03852   0.02448   0.02341         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.503G   0.03747   0.02413   0.02125        10       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.503G   0.03671   0.02467   0.02105         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.503G   0.03474   0.02482   0.01907         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.503G   0.03484   0.02363   0.01811        25       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.503G   0.03401   0.02344   0.01738         1       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.752      0.646       0.71      0.409\n",
      "\n",
      "25 epochs completed in 0.426 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▇▅▅▅▄▄▃▃▃▃▂▂▂▂▃▂▂▂▁▁▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.7096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.40902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.75211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.64617\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.7096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.40902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.75211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.64617\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03401\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01792\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02506\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00054\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00054\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00054\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfeasible-eon-511\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3j6v9y7i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220728_030703-3j6v9y7i/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m24 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.75211,              0.64617,               0.7096,              0.40902,             0.035404,             0.025061,              0.01792,              0.00609,                 0.01,              0.92501,              0.00046,                3.044,               0.8586,              0.09795,              0.05176,               0.5398,              0.97224,               1.3152,              0.90869,                  0.2,               3.1991,                    0,              0.01402,              0.48381,              0.30328,                    0,              0.10739,              0.42237,                    0,                    0,                    0,                  0.5,              0.80816,                    0,                    0,                    3\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00665, lrf=0.01, momentum=0.89664, weight_decay=0.00045, warmup_epochs=3.27868, warmup_momentum=0.90108, warmup_bias_lr=0.12704, box=0.05137, cls=0.51574, cls_pw=0.94751, obj=1.29272, obj_pw=0.90669, iou_t=0.2, anchor_t=3.30039, fl_gamma=0.0, hsv_h=0.01112, hsv_s=0.47372, hsv_v=0.3273, degrees=0.0, translate=0.0957, scale=0.46468, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.92316, mixup=0.0, copy_paste=0.0, anchors=2.80979\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220728_033324-3rt644dm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdeft-sunset-512\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3rt644dm\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=2.80979\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00045\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:33<00:00, 32.8\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.10 anchors/target, 0.028 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8029: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.30: 1.0000 best possible recall, 6.33 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.447/0.803-mean/best, past_thr=0.557-mean: 17,15, 26,25, 43,27, 32,42, 53,42, 48,69, 79,64, 120,104, 216,258\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.501G    0.1001   0.03986   0.07266         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.501G   0.06984   0.03821   0.06562         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.501G   0.06789   0.03368   0.06384         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.503G   0.06171   0.03365   0.06181         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.503G   0.05633   0.03204   0.05904         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.503G   0.05121   0.02979   0.05644         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.503G   0.04813   0.03004   0.05349         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.503G   0.04788   0.03085   0.05188         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.503G   0.04661   0.02877   0.05001         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.503G   0.04591   0.02899   0.04734         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.503G   0.04432   0.02915   0.04545         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.503G   0.04413   0.02793   0.04271         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.503G   0.04214   0.02765    0.0398         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.503G   0.04176   0.02769   0.03685         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.503G   0.04226   0.02799   0.03537         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.503G   0.04116   0.02699   0.03365         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.503G   0.03853   0.02689   0.03073         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.503G   0.04012   0.02639   0.02914         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.503G   0.03803   0.02556    0.0279         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.503G    0.0385   0.02682   0.02709         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.503G   0.03708    0.0249   0.02516         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.503G   0.03601   0.02683   0.02467         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.503G    0.0358   0.02565   0.02448         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.503G   0.03505   0.02626   0.02395         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.503G   0.03427   0.02544   0.02176         2       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.678      0.628      0.653      0.378\n",
      "\n",
      "25 epochs completed in 0.428 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▅▄▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▇▆▆▅▅▅▅▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▇▅▅▄▃▃▄▃▃▃▂▂▂▂▂▂▂▁▂▁▂▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▅████▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▅████▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.6529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.37754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.67833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.62798\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.6529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.37754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.67833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.62798\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03427\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02544\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03508\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02506\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdeft-sunset-512\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3rt644dm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220728_033324-3rt644dm/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m25 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m             0.67833,              0.62798,               0.6529,              0.37754,             0.035081,             0.025062,             0.022069,              0.00665,                 0.01,              0.89664,              0.00045,               3.2787,              0.90108,              0.12704,              0.05137,              0.51574,              0.94751,               1.2927,              0.90669,                  0.2,               3.3004,                    0,              0.01112,              0.47372,               0.3273,                    0,               0.0957,              0.46468,                    0,                    0,                    0,                  0.5,              0.92316,                    0,                    0,               2.8098\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00675, lrf=0.01, momentum=0.91705, weight_decay=0.00032, warmup_epochs=2.68998, warmup_momentum=0.84139, warmup_bias_lr=0.13545, box=0.0479, cls=0.57794, cls_pw=0.83881, obj=1.34991, obj_pw=0.97011, iou_t=0.2, anchor_t=3.401, fl_gamma=0.0, hsv_h=0.01477, hsv_s=0.47168, hsv_v=0.30537, degrees=0.0, translate=0.10639, scale=0.44635, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.92268, mixup=0.0, copy_paste=0.0, anchors=3.7114\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220728_035952-3ahb7ks7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtrue-glitter-513\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3ahb7ks7\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=3.7114\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     79112  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7085256 parameters, 7085256 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.00032\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:33<00:00, 32.6\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.35 anchors/target, 0.081 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 12 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8237: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.29: 1.0000 best possible recall, 8.34 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=12, img_size=640, metric_all=0.438/0.824-mean/best, past_thr=0.551-mean: 16,14, 27,22, 23,34, 37,36, 49,28, 37,52, 57,45, 58,70, 82,62, 116,99, 193,125, 289,266\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.499G    0.0983   0.04376   0.07554         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.499G   0.06843    0.0408   0.06931         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.499G   0.06631   0.03717   0.06598         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.499G   0.05546   0.03469   0.06487         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.499G   0.04987   0.03373   0.06282         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.499G   0.04584   0.03247   0.06038         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.499G   0.04348   0.03207   0.05715         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.499G   0.04211   0.03189   0.05519         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.499G   0.04221   0.03156   0.05304         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.499G   0.04063   0.03154   0.05022         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.499G   0.03939   0.03036   0.04803         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.499G   0.03927   0.03106   0.04619         0       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.499G   0.03835   0.02957   0.04416         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.499G   0.03757   0.03017   0.04251         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.499G   0.03913    0.0303   0.03997         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.499G   0.03754   0.02849   0.03867         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.499G   0.03632   0.02834   0.03626         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.499G   0.03574   0.03018   0.03541         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.499G   0.03479   0.02811   0.03202         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.499G   0.03472   0.02861    0.0309         7       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.499G    0.0339   0.02656   0.03043         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.499G   0.03328   0.02679     0.029         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/24    0.499G   0.03276   0.02713    0.0279         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/24    0.499G   0.03273   0.02692   0.02657         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/24    0.499G    0.0317   0.02673    0.0247         4       640: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        277        616      0.634      0.586      0.627      0.369\n",
      "\n",
      "25 epochs completed in 0.428 hours.\n",
      "Results saved to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▅▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▇▇▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▇▅▄▄▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆███▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.6268\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.36929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.634\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.58553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.6268\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.36929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.634\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.58553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0247\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02648\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mtrue-glitter-513\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/3ahb7ks7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220728_035952-3ahb7ks7/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m26 generations finished, current result:\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
      "\u001b[34m\u001b[1mevolve: \u001b[0m               0.634,              0.58553,               0.6268,              0.36929,             0.032184,             0.026483,             0.027042,              0.00675,                 0.01,              0.91705,              0.00032,                 2.69,              0.84139,              0.13545,               0.0479,              0.57794,              0.83881,               1.3499,              0.97011,                  0.2,                3.401,                    0,              0.01477,              0.47168,              0.30537,                    0,              0.10639,              0.44635,                    0,                    0,                    0,                  0.5,              0.92268,                    0,                    0,               3.7114\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00592, lrf=0.01081, momentum=0.92179, weight_decay=0.0004, warmup_epochs=2.99956, warmup_momentum=0.81822, warmup_bias_lr=0.12132, box=0.05903, cls=0.61401, cls_pw=0.94327, obj=1.1684, obj_pw=1.00378, iou_t=0.2, anchor_t=4.32816, fl_gamma=0.0, hsv_h=0.01205, hsv_s=0.5214, hsv_v=0.27336, degrees=0.0, translate=0.09516, scale=0.45722, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3.0\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/root/mgozzi-augment/wandb/run-20220728_042620-273qdaz9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfearless-deluge-514\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mbari/902005-vaa/runs/273qdaz9\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "Overriding model.yaml anchors with anchors=3.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     59334  models.yolo.Detect                      [17, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7065478 parameters, 7065478 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from deepsea-yolov5/yolov5/yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "Scaled weight_decay = 0.0004\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/images/train/1f66e28c-3fcf-464b-a4c3-17a6df88685b.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100%|██████████| 1105/1105 [00:34<00:00, 32.4\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/root/mgozzi-augment/deepsea-yolov5/opt/ml/input/data/labels/val.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.19 anchors/target, 0.051 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 2445 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8032: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 7.16 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.444/0.803-mean/best, past_thr=0.521-mean: 15,13, 25,24, 39,26, 31,42, 51,40, 50,68, 77,61, 120,98, 270,263\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m902005-vaa/exp72\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/24    0.501G    0.1246   0.04311   0.08824         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/24    0.501G     0.089   0.04093   0.08005         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/24    0.501G   0.08236   0.03773   0.07578         9       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/24    0.501G   0.07302   0.03653   0.07404        17       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/24    0.501G   0.06391   0.03586    0.0708         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/24    0.501G   0.06202   0.03558   0.06592         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/24    0.501G   0.05675    0.0341   0.06132         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/24    0.501G   0.05612   0.03355   0.05884         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/24    0.501G   0.05659   0.03506   0.05549         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/24    0.501G    0.0542   0.03394   0.05093         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/24    0.501G   0.05338   0.03245   0.04646         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/24    0.501G   0.05226   0.03229   0.04375         4       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/24    0.501G   0.05127   0.03053   0.04056         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/24    0.501G   0.04949     0.032   0.03694         3       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/24    0.501G   0.04932   0.03043   0.03445         1       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/24    0.501G   0.04913   0.03063   0.03315         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/24    0.501G   0.04767   0.03236   0.03048         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/24    0.501G    0.0468   0.02945     0.028         5       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/24    0.501G    0.0453    0.0296   0.02634         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/24    0.501G   0.04516   0.02885   0.02472         6       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/24    0.501G   0.04504   0.02957   0.02328         2       640: 100%|███\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/24    0.501G   0.04364    0.0285     0.022        10       640:  85%|███"
     ]
    }
   ],
   "source": [
    "# if training for evolutions, set epochs to 25, and evolve to 30\n",
    "# if you desire to graph the evolution with the hyperparameters, add the --hyp path and change the hyperparameter.yaml file located in opt/ml/input/data/hyp.scratch-low.yaml\n",
    "!export WANDB_RUN_GROUP=\"evolution_const_seed\" && python ./deepsea-yolov5/yolov5/train.py \\\n",
    "--img=640 \\\n",
    "--data=./deepsea-yolov5/opt/ml/custom_config.yaml  \\\n",
    "--batch=2 \\\n",
    "--cfg=./deepsea-yolov5/yolov5/models/yolov5s.yaml \\\n",
    "--project=\"902005-vaa\"\\\n",
    "--cache \\\n",
    "--epochs=25 \\\n",
    "--evolve=35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Train Using Current Hyperparameter File\n",
    "***VERY IMPORTANT*** Before running the 50 epochs with the optimal hyperparameters, it is crucial that you copy the anchor points outputted during the evolution runs. Update the <code>yolov5*.yaml</code> file with these values and ensure that the <code>--noautoanchor</code> flag is used. The model file is located under <code>yolov5/models/</code>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;31m# know whether we've finished (if we matched EOF) or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mres_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;31m# Still have time left, so read more data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mread_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# (possibly timeout=None), we call select() with a timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mselect_ignore_interrupts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild_fd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pexpect/utils.py\u001b[0m in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miwtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mewtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-08beb17c2b90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Change the contents of the deeosea-yolov5/opt/ml/input/data/hyp.scratch-low.yaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# to utilize the best found hyperparameters from the evolutions performed above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'export WANDB_RUN_GROUP=\"hyperparam_const_seed\" && python ./deepsea-yolov5/yolov5/train.py  --img=640  --data=./deepsea-yolov5/opt/ml/custom_config.yaml   --batch=2  --cfg=./deepsea-yolov5/yolov5/models/yolov5s.yaml  --hyp=./deepsea-yolov5/opt/ml/input/data/hyp.scratch-low.yaml  --project=\"902005-vaa\" --cache  --epochs=50'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0;31m# Ensure new system_piped implementation is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;31m# Ensure the subprocess really is terminated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;31m# add isalive check, to ensure exitstatus is set:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGCONT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterterminate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Change the contents of the deeosea-yolov5/opt/ml/input/data/hyp.scratch-low.yaml \n",
    "# to utilize the best found hyperparameters from the evolutions performed above. \n",
    "!export WANDB_RUN_GROUP=\"hyperparam_const_seed\" && python ./deepsea-yolov5/yolov5/train.py \\\n",
    "--img=640 \\\n",
    "--data=./deepsea-yolov5/opt/ml/custom_config.yaml  \\\n",
    "--batch=2 \\\n",
    "--cfg=./deepsea-yolov5/yolov5/models/yolov5s.yaml \\\n",
    "--hyp=./deepsea-yolov5/opt/ml/input/data/hyp.scratch-low.yaml \\\n",
    "--project=\"902005-vaa\"\\\n",
    "--cache \\\n",
    "--epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a sweep (doesn't work well yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "\n",
    "import os\n",
    "os.environ['WANDB_PROJECT']=\"902005-vaa\"\n",
    "\n",
    "!wandb sweep deepsea-yolov5/yolov5/utils/loggers/wandb/sweep.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace mbari/.../... with output from command above\n",
    "!wandb agent mbari/902005-vaa/w8krnvak"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.10-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "10473cd72beb9f903a0df0895b8cbe75ad84c2c6b795c916562cda13d35a2cb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
